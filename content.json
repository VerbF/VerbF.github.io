{"pages":[{"title":"about","text":"联系我Email:xixiangshu704@qq.com","link":"/about/index.html"}],"posts":[{"title":"基于 Mask R-CNN 的鸟类识别 app","text":"一个基于 Mask R-CNN 的鸟类识别 APP，可以识别五种鸟类，mAP 83%。 前言这时博主的毕设的课题，时间紧迫加上自身能力所限，最后的作品还有很多不足，还望各位不吝指正。代码已经上传到了 github,并附上了详细的使用说明。先放一下效果图 概述整个系统包括用户端和服务端两部分。用户端通过 http 协议将待识别的鸟类图片上传到服务端，服务端再将识别后的图片和鸟类信息返回给用户端。 鸟类识别由 Mask R-CNN 框架训练出的模型完成。 鸟类识别博主标注了 5 类，共 300 张鸟类图片，使用 Mask R-CNN 框架进行训练，得到了识别鸟类的模型。 5 种鸟类的图片 平均准确率的统计图 用户端用户端运行在安卓系统上，包括图片的选择，图片的裁剪，图片的上传，以及识别结果的显示等功能。 服务端服务端采用Python编程语言进行编写，服务端完成了接收用户端上传图片，识别图片，从数据库中查询鸟类的信息，将识别的结果回传到用户端等功能。 服务端使用了 flask web 应用框架。执行 server.py 脚本后服务启动，当服务端接收到用户端上传的鸟类图片时将会调用 detect.py 脚本，脚本调用模型对鸟类进行识别。","link":"/post/bird-identification-app/"},{"title":"深度学习专项课程（2）（第一周）","text":"这是 DeepLearning.ai 微专业的第二门课《改善深层神经网络：超参数调试、正则化以及优化》第一周的课程。 数据集划分我们通常将数据集划分为训练集 training set，简单交叉验证集（验证集）dev set，测试集 test set。我们使用不同的模型在训练集上进行训练，使用验证集对训练出的模型进行比较，选出最优的模型。最后使用测试集对模型进行评估。如果数据集较小，可以根据 60%，20%，20%来划分数据集。如果数据集达到了百万级，那么按照 98%，1%，1%来划分也是可以的。 偏差和方差我们可以观察模型的拟合情况来判断偏差和方差处于何种状态。如下图所示，如果模型欠拟合，我们称之为高偏差。如果模型过拟合，则称之为高方差 在多位空间数据中绘制数据和可视化分割边界无法实现，我们可以通过几个指标来研究方差和偏差。下面举个例子：在判断是否是猫的问题上，人类可以做到几乎不出错，即错误率约为 0% 。当算法在训练集上准确率错误率为 1% 时，我们认为算法表现良好。如果算法在训练集上表现较好，而验证集上表现较差，那么我们称之为 高方差。下面的表格给出了错误率与方差偏差之间的关系。 Test set error Dev set error bias/variance 1% 11% high variance 15% 16% high bias 15% 30% high bias &amp; high variance 0.5% 1% low bias &amp; low variance 正则化有关正则化的先关内容已在机器学习的课程中详述过，这里不再记录。 L1 正则化如果使用 L1 正则化，w 最终会是稀疏的，即矩阵中会有很多的 0 。 正则化项： $$ \\large \\frac{\\lambda}{2m}||w||_1=\\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}|w_j| $$ L2 正则化目前人们更倾向于使用 L2 正则化 正则化项： $$ \\large\\frac{\\lambda}{2m}||w||^2_2=\\frac{\\lambda}{2m}\\sum_{j=1}^{n_x}w_j^2 = \\frac{\\lambda}{2m} w^Tw $$ 这里为什么不正则化参数 b 呢？其实可以加上参数 b ，但因为参数 w 通常是一个高维参数矢量已经可以代表搞偏差的问题，w 已含有很多参数，我们不可能拟合所有参数，而 b 只是单个数字，加或不加其实并没有太大的影响。 Dropout（随机失活） 正则化dropout 是一种另一种实用的正则化方法， dropout 会遍历网络的每一层，并设置消除神经网络节点中的概率。下图中我们设置每个节点保留和消耗的概率都是 0.5 ，在消除掉某些节点之后我们就得到了一个节点更少，规模更小的网络，然后使用反向传播算法进行训练，这时网络节点精简后的一个样本。对于其它样本，依旧按概率随机消除节点。对于每个训练样本，我们都将采用一个精简后的神经网络来训练它。 在测试阶段的时候不应该使用 dropout ，否则的话我们每次测试的结果预期值都不相同。 如何理解 dropout ？从直觉上来理解，因为每次消除的节点不相同，所以神经网络不能依赖于任何一个单独的节点，它将权值分散在各个节点上。 参数扩增很多时候增加数据集的代价很高，我们可以通过人工的方式扩增数据集。比如对于图片的数据集，我们可以对其做水平翻转，或是增加噪声等等。 early stopping从下图中我们可以看到，随着迭代次数的增加训练集的误差逐渐减少，而测试集的误差在开始时下降，随后开始增加。我们只要在测试集的误差开始增加之前停止训练，就可以防止出现过拟合的情况。 但这个方法也有缺点，即训练集的误差无法降到最小。 归一化输入归一化输入是加速训练神经网络的一种方法。 归一化输入需要两个步骤，第一步是 零均值化。 $$\\mu = \\frac{1}{m}\\sum_{i=1}^m \\x = x - \\mu$$ 这一步相当于对数据集做了移动 第二步是归一化方差。从上面的图中可以看出，特征 x1 的方差比特征 x2的方差要大很多 $$\\sigma^2 = \\frac{1}{m}\\sum_{i=1}^mx^{(i)}**2 \\x \\quad/= \\sigma^2$$ 最后的结果如图所示 注意，应该用同一组 $\\mu$ 和 $\\sigma^2$来调整 训练集和测试集。 经过归一化的数据，在执行梯度下降时速度更快。 梯度消失与梯度爆炸梯度消失与梯度爆炸是指当训练神经网络时，梯度或坡度会变得很大，或非常小，甚至以指数的形式变小。如下图，当网络的层数很深时，梯度层层相乘，如果梯度比 1 大一点点，最后也会变得非常大。相反，如果梯度比 1 小一点点，最后也会变得非常小。 权重初始化虽然不能从根本上解决梯度消失和梯度爆炸的问题，但以合适的方法初始化权重可以减少其影响。假设某层输入特征数量为 n，我们可以将权值矩阵初值设置为 随机值* $\\sqrt{\\frac{1}{n}}$ $$ \\large W^{[l]} = np.random.radn(shape) * np.sqrt(\\frac{1}{n^{[l-1]}}) $$ 梯度检验如何判断反向传播正确的工作了呢？可以使用下面的方法对其进行检验。核心思想是使用一个导数计算的近似公式求出导数，并与反向传播算法得出的结果进行比较，在一定的误差范围内，我们就可以认为反向传播算法正常工作。 实施注意事项 不要用在训练中，仅仅在调试时使用。 如果梯度检验失败，需要详细检查相关项 注意正则化 不能与 dropout 同时使用 如果效果不理想，可以尝试重新训练","link":"/post/deeplearning-ai-2-week-1/"},{"title":"深度学习专项课程（2）（第二周）","text":"本周主要讲解了一些优化的算法。 Mini-batch 梯度下降法我们在执行梯度下降法时，会使用向量化的方法来加速计算。但如果训练集的数量很大时，速度仍然很慢。Mini-batch 梯度下降法可以加快训练的速度。使用传统的梯度下降法训练一次会处理所有的样本，而 Mini-btach 梯度下降法每次只处理部分的样本。Mini-batch 梯度下降法每次处理样本的数量需要我们自己选择，设定的数量过大或过小都不合适。在极端情况下，设定数量为 1 （即随机梯度下降法，每次只处理一个样本），这样将失去向量化带来的加速效果，这样效率过于低下。设定数量为样本的总数时（即batch梯度下降法），单次迭代的速度会过慢。所以应将数量设置在中间的位置。 指数加权平均后面将讲到一些高级的优化算法，在这之前需要了解“指数加权平均”的概念。 上图中蓝色的点表示伦敦在一年中每天的温度。如果我们要计算趋势的话，也就是温度的局部平均值，我们可以这样做：$\\theta_i$ 表示第 i 天的温度。 $$\\largev_0 = 0 \\\\v_1 = 0.9v_0 + 0.1\\theta_1 \\\\v_1 = 0.9v_1 + 0.1\\theta_2 \\\\v_1 = 0.9v_2 + 0.1\\theta_3 \\\\v_1 = 0.9v_3 + 0.1\\theta_4 \\\\v_1 = 0.9v_4 + 0.1\\theta_5 \\\\…$$ 公式就是：$v_t = \\beta v_{t-1} + (1-\\beta)\\theta_t$ 下图中红色的线时 $\\beta=0.9$ 的图像，绿色的线是$\\beta=0.98$的图像。 $\\beta$ 的值越大，曲线就越平缓，因为此时平均的天数更多，但也因为这样曲线进一步右移。可以看出绿色的线对于蓝色的点的趋势有一定的延迟。 事实上，上面的图并不是实际的情况。如果我们设定$\\beta = 0.98$ 我们得到的并不是绿色的线，而是下图中紫色的线。两条线相比，紫色线的起点更低，这是因为我们设置了 $v_0=0$，显然这与实际的数据是由出入的，即有偏差。如果想修正偏差，可以将公式中的$v_t$换成$\\frac{v_t}{1-\\beta_t}$。其中 t 表示天数。当 t 很小时（且 $\\beta &lt; 0$），$v_t$ 除以一个小于 1 的数字将变大，当 $v_t$ 变得很大时，$\\beta^t$ 约等于 0 ，$v_t$ 的值基本不变。这样就实现了修正偏差。然而在机器学习中人们并不在意修正偏差，而更愿意熬过初期获得更精确的预测值。如果你想在初期获得较精确的预测值，可以使用修正偏差。 动量梯度下降法momentum 梯度下降法运行速度几乎总是快于标准的梯度下降法，其基本思想计算梯度的指数加权平均数，并利用该梯度更新权重。 上面是一个梯度下降的例子，因为样本中存在噪声，所以每一次梯度下降的方向并不是严格的指向最优点。这样在上下的方向上存在一个速度分量，我们看作是纵轴，左右方向上存在一个速度分量，我们看作是横轴。我们希望加快在横轴上的速度，而减缓在纵轴上的速度，这样可以更快的完成训练。 我们修改一下参数更新的公式，将上一节讲到的指数加权平均加入其中： $$\\largeV_{dw} = \\beta V_{dw} + (1-\\beta)dw \\\\V_{db} = \\beta V_{db} + (1-\\beta)db \\\\w = w -\\alpha V_{dw} \\\\b = b -\\alpha V_{db}$$ 上图中红色的线代表动量梯度下降法的轨迹，可以看到它在纵轴上的震荡变缓了。但是动量梯度下降法并不是在所有情况下都有效，它只对于碗状的函数有效。 RMSpropRMSprop(root mean square prop)算法亦可以加速梯度下降，让我们来看看它是如何运行的。 同样的，我们希望可以加快在横轴上的学习，而减缓在纵轴上的学习。为了方便起见，将横轴上的参数记为 w ，纵轴上的参数记为 b ，我们将公式更新如下： $$\\largeS_{dw} = \\beta S_{dw} + (1-\\beta)(dw)^2 \\\\S_{db} = \\beta S_{db} + (1-\\beta)(db)^2 \\\\w = w - \\alpha \\frac{dw}{\\sqrt{S_{dw}}} \\\\b = b - \\alpha \\frac{db}{\\sqrt{S_{db}}}$$ 由图可知，在纵轴上的斜率较大，横轴上的斜率较小，即 $S_{db} &gt; S_{dw}$ 。从公式中可以看到 dw 除以了一个较小的值，那么 w 的变化将变快。 db 除以一个较大的值 ，则 b 的变化将变小。这就是 RMSprop 算法的思想。 需要注意的是，这里的 w 和 b 在实际的应用中可能是高维的向量。为了防止发生除 0 的错误，我们做如下改动($\\epsilon$ 是极小的值)： $$\\largew = w - \\alpha \\frac{dw}{\\sqrt{S_{dw}}+\\epsilon} \\\\b = b - \\alpha \\frac{db}{\\sqrt{S_{db}}+\\epsilon}$$ Adam 优化算法Adam（Adaptive Moment Estimation） 算法可以看作是 动量梯度下降算法 和 RMSprop算法 的结合。这里直接给出公式，这里我们使用了修正偏差： $$ \\large V_{dw} = \\beta_1 V_{dw} + (1-\\beta_1)dw , V_{db} = \\beta_1 V_{db} + (1-\\beta_1)db \\quad \\leftarrow'momentun' \\quad \\beta_1 \\\\\\ S_{dw} = \\beta_2 S_{dw} + (1-\\beta_2)(dw)^2 , S_{db} = \\beta_2 S_{db} + (1-\\beta_2)(db)^2 \\quad \\leftarrow 'RMSprop'\\quad \\beta_2 \\\\\\ V_{dw}^{corrected} = V_{dw}/(1-\\beta_1^t) , V_{db}^{corrected} = V_{db}/(1-\\beta_1^t) \\\\\\ S_{dw}^{corrected} = S_{dw}/(1-\\beta_2^t) , S_{db}^{corrected} = S_{db}/(1-\\beta_2^t) \\\\\\ w = w - \\alpha \\frac{V_{dw}^{corrected} }{\\sqrt{S_{dw}^{corrected}}+\\epsilon} \\\\\\ b = b - \\alpha \\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}}+\\epsilon} $$ 这样就将两个算法结合起来了。 学习率衰减加快学习算法的另一个方法就是随时间慢慢减少学习率，我们将它称为学习率衰减。 在训练的过程中，第一次遍历数据集我们记作 epoch 1，第二次记作 epoch 2 。。。 以此类推。我们将学习率设为: $$\\alpha = \\frac{1}{1 + decay-rate * epoch-num}\\alpha_0$$ 这样学习率就会随着迭代次数的增加而递减。除此之外，还有多种方法进行学习率衰减，此处不一一列举。 局部最优的问题过去研究人员会担心某些算法会陷入局部最优点，无法到达全局最优点。然而随着研究的深入，人们并不把这当作一个问题。 对于低维的数据在我们的脑海中往往出现这样一幅图像： 可以看到，在这幅图像中存在着许多局部最优点，可能会对算法造成影响。这样的想法影响了我们对高维数据的理解。在高维数据中我们通常不会遇到局部最优点，而是鞍点。 可以看到鞍点并不是在所有维度上的梯度都为 0 ，所以算法可以逃离鞍点。事实上，在高维的局部最优点很难遇到，它需要在各个维度上的梯度都为 0 才能满足，而这样点出现的概率非常低。所以说这并不是一个问题。 然而在算法达到鞍点时，训练的速度将变的十分缓慢，如何加速训练的速度这才是我们需要关注的问题。","link":"/post/deeplearning-ai-2-week-2/"},{"title":"深度学习专项课程（2）（第三周）","text":"本周介绍了超参数调整，bath归一化以及程序框架的相关内容。 超参数调试神经网络的改变会涉及到许多超参数的设置，这一节我们将介绍一些超参数调整的指导性原则。虽然超参数的数量很多，但它们的重要性却不相同。例如超参数学习率 $\\alpha$ 的重要性通常要高于其他的超参数。在涉及多个超参数的调整时，我们可以根据下面的方法来处理： 我们假设有两个超参数$\\alpha$和$\\epsilon$，如上图的左边，我们在网格中均匀的选取采样点进行测试。但因为超参数的重要性不同，$\\epsilon$ 值的改变可能对结果没有影响，而$\\alpha$的在这里只使用了 5 个值进行测试。如果我们采用上图右边的方式，随机选取值来进行测试，这样就可使超参数的取值个数变多。如果有三个超参数，那值的选取将在三维的立方体中进行。 另一个调整超参数的方法是”粗糙到精细” ，如果我们再网格中发现某一区域内的值较好，我们可以将此区域放大，进行更精细的取值。 超参数范围选取上一节中说到，随机取值可以提升你的搜索效率，但随机取值并不是在有效值范围内的随机均匀取值，而是选择合适的标尺用于探究这些超参数。 这里简单的说明随机均匀取值会有什么样的影响。假设参数 $\\alpha$ 的取值范围是 0.0001 到 1 ，如果我们随机均匀取值的话，0.1 到 1 将需要 90% 的搜索资源，而 0.0001 到 0.1 只分到了 10% 的搜索资源，显然这并不是一个好的方法。 所以我们采用对数坐标轴来解决这个问题。我们在对数坐标轴上随机均匀取点，这样在 0.0001 到 0.001 之间就会有更多的搜索资源可用。 如果我们想将 $\\alpha$ 的范围设置在 [0.0001,1] 之间,在 python 中 我们可以这样设置范围： $$\\larger = -4*np.random.rand() \\leftarrow r \\in [-4,0] \\\\\\alpha = 10^r \\leftarrow \\alpha \\in [0.0001,1]$$ Pandas VS Caviar这里再给出一些设置超参数的方法。 当我们的机器只能负担起实验一个模型或一小批模型时，我们通常采用这个方法。即每次实验一个模型，根据实验的结果修改超参数。然后再使用修改后的超参数训练模型，再根据此次实验的结果改进超参数，如此迭代。这种方法 AndrewNg 比喻为 pandas。 如果机器可以负担起多次平行实验，那就可以同时训练有不同超参数的模型，再根据实验的结果取得超参数的最优值。这种方法与鱼类生殖的方式相似，故比喻为 caviar（鱼子酱）。 batch 归一化在前面的课程中我们提到过，归一化输入特征可以加速学习过程。归一化的步骤如下： $$\\large\\mu = \\frac{1}{m}\\sum x^{(i)} \\\\x = x - \\mu \\\\\\sigma^2 = \\frac{1}{m} \\sum (x^{(i)})^2 \\\\x = x/ \\sigma^2$$ 在神经网络中隐藏层的神经单元是没有输入特征的，所以我们要做的是对上一层传递过来的激活值进行归一化处理。我们知道一个神经元计算过程可分为两步，第一步是加权求和得到 z 值，第二步是将 z 放入激活函数中求出激活值。 归一化的对象就是 z 。 下面是具体的步骤： $$\\large\\mu = \\frac{1}{m} \\sum z^{(i)} \\\\\\sigma^2 = \\frac{1}{m} \\sum (z_i - \\mu)^2 \\\\z_{norm}^{(i)} = \\frac{z^{(i)} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\\\\\widetilde{z}^{(i)} = \\gamma z_{norm}^{(i)} + \\beta$$ 这里 $\\gamma$ 和 $\\beta$ 的作用是可以随意设置 $\\widetilde{z}$ 的平均值。如果不加入这两个参数，仅使用 $z_{norm}^{(i)}$ 作为最后的值，那么的平均值和方差是固定的。但我们并不想所有的隐藏单元都有同样的分布，这样才能学到有趣的特征，所以需要加入这两个参数。需要注意的是，这两个参数也是需要学习的 下图展示了如何在深层神经网络中实现 batch 归一化。 那么 batch 归一化 为什么有用呢？ 可以这样理解，它减弱了前层参数的作用与后层参数的作用之间的联系，它使得每层网络可以自己学习，稍稍独立于其他层，这有助于加速整个网络的学习。事实上，batch 归一化 还有一点轻微的正则化作用。 batch 归一化 常和 mini-batch 的方法一起使用。考虑这样一个问题，在测试时如何计算$\\mu$ 和 $\\sigma^2$的值呢？可以这样解决，在训练时可以记录下不同 mini-batch 下对应的 $\\mu$ 和 $\\sigma^2$。在测试时，使用指数加权平均的方法来估计两个参数的值。 softmax 回归原理到目前为止，所提到的分类例子都用了二分类，如果有多种分类的话可以使用 softmax 回归。我们来看看 softmax 的原理是什么： 在神经网络的最后一层，先计算出 $z^{[l]}$ 的值，在将其输入到激活函数中。这里的激活函数输入值是一个向量，输出值也是一个同样维度的向量。思想就是将向量中的每个元素取幂，这样每个元素都为正数。再将每个元素除以所有元素之和，这样之后，所有元素均小于 1，大于 0 ，且所有元素之和为 0。最后向量的值可以看作是对应的概率。 $$\\largez^{[l]} = w^{[l]}a^{[l-1]} + b^{[l]} \\\\activation\\quad function: \\\\t = e^{(z^{[l]})} \\\\a^{[l]} = \\frac{e^{z^{[l]}}}{\\sum^4_{j=1} t_i} \\quad ,\\quad a^{[i]}_i = \\frac{t_i}{\\sum^4_{j=1} t_i} \\\\$$ 代价函数$$\\largel(\\hat{y},y) = -\\sum^4_{j=1}y_j log\\hat{y}_j$$ 其中 y 代表真实值， $\\hat{y}$ 代表预测值。 $$y^{(i)} = \\begin{bmatrix}0 \\\\ 1 \\\\ 0 \\\\ 0\\end{bmatrix} ,\\hat{y}^{(i)} = \\begin{bmatrix}0.3 \\\\ 0.2 \\\\ 0.1 \\\\ 0.4\\end{bmatrix}$$ 我们将对应的 y 值带入到代价函数中发现，如果对应真值的概率越高则代价越小，若概率越低则代价越大。","link":"/post/deeplearning-ai-2-week-3/"},{"title":"深度学习专项课程（3）（第一周）","text":"本文内容是 deep_learning.ai 微专业的第三门 《构建机器学习项目》第一周的课程。 这门课的内容与如何更快速高效地优化机器学习系统有关。 正交化搭建机器学习系统的挑战之一是我们可以尝试和修改的东西太多了，比如说有许多的超参数可以调整。许多高效的机器学习专家非常清楚要达到某种效果需要调整那些参数，这个过程我们称为正交化。 看下面的例子： 在老式的电视中有许多旋钮可以调整电视的画面，如有些旋钮可以调节画面的横向宽度，有的可以调节纵向的宽度等等。这些旋钮都独立的负责某一功能，这样我们就可以通过调节不同的旋钮达到自己想要的效果。但如果某个旋钮同时具备了两个功能，那么我们在调节的时候可能并不会那么容易。这就是正交化的一个简单的例子。 同样的，在机器学习系统中我们也可以设置类似的“旋钮”来实现不同的独立的功能。例如可以设置某个“旋钮”可以调节训练集的大小，或是切换不同的优化算法等等。 单一数字评估指标在前面提到过的猫分类器，我们可以通过 precision 和 recall 这两个指标来评价一个🐱分类器的好坏。但如果我们有多个🐱分类器的话如何来评价它们的优劣呢？我们需要一个单一数字评估指标，在这里我们将 precision 和 recall 两个指标结合起来得到一个新的指标 F1 Score（可以理解为 precision 和 recall 的某种平均值） , 这样我们就可以通过 F1 Score 这个指标来快速的比较不同分类器之间的好坏了。 满足和优化指标有时候要把我们所有顾及的事情结合成单一数字评估指标是不容易的，在这样的情况下，设置满足和优化指标是很有用的。 classifier accuracy runtime A 90% 80ms B 92% 95ms C 95% 1500ms 假设我们决定很看重分类器的 accuracy 和 runtime 两个指标，我们可以把这两个指标以某种方式结合成单一数字评估指标。但是这样并不是最好的方法，因为就 runtime 这一指标而言，只要其值小于 100ms，那么 80ms 和 95ms 对用户来说并没有太大的差别，但用户对 accuracy 的要求更高。所以我们可以将 runtime 设置为满足指标，而将 accuracy 设置为优化指标。 人的表现我们在评估一个机器学习系统的性能时，常常会将其与人类的表现进行对比。这是为什么呢？ 这里需要提到贝叶斯最优错误率，贝叶斯最优错误率一般认为时理论上可能达到的最优错误率。也就是说没有任何办法可以设计出一个 x 到 y 的函数可以使它的准确度能够超过一定的标准。而人类在某些方面十分擅长，几乎接近了贝叶斯最优错误率。所以在某些时候可以用人类的表现来估计贝叶斯最优错误率。 另一个方面是当机器学习系统准确率在超过人类的表现之后，想要在提升准确率就会变得非常缓慢。这有两个原因，第一个就是上面提到的人类的表现已经很接近贝叶斯最优错误率了。第二个原因是当机器的准确率未达到人类的表现时有很多工具可以帮助机器提升准确率，例如可以让人类对数据进行标注等。而当机器的准确率超过人类的表现后则没有相应的工具了。 可避免偏差 Humans（$\\approx$ Bayes） 1% 7.5% Training error 8% 8% Dev error 10% 10% 我们将贝叶斯错误率和训练集上的错误率之差称为可避免偏差。 在上面左边的例子中可避免偏差为7%，而训练集与开发集的方差为 2%，在这样的时候我们应考虑减少可避免方差。 在右边的例子中可避免偏差为 0.5%，而训练集与开发集的方差仍为 2%，所以我们应该将精力放到减少方差上。 改善你的模型表现","link":"/post/deeplearning-ai-3-week-1/"},{"title":"深度学习专项课程（第一周）","text":"“深度学习”指的是训练神经网络，那么神经网络到底是什么呢？ 什么是神经网络我们还是从一个预测的例子开始。我们有关于房屋尺寸和价格的样本集，我们想要通过这个样本来预测房屋的价格。我们可以通过线性回归来解决这个问题。但我们知道房屋的价格不可能为负数，所以我们对这个函数稍作修改，使其不为负数，如下图所示。这个函数我们称为 ReLU（线性整流函数，Rectified Linear Unit, ReLU） 函数 这就可以看做是一个几乎是最简单的神经网络了。 我们把它换一个形式画出来，如下图所示。我们把 房屋面积 size 作为神经网络的输入，中间的圆圈我们将它称为一个独立的神经元，房屋的价格为神经网络的输出。这个神经网络完成了上面图中的功能，神经元的作用就是输入面积，完成线性运算，取不小于 0 的值，最后输出房屋的预测价格。 我们可以将神经元想象成乐高积木，我们将神经元堆叠起来可以形成更大的神经网络。我们来可一个例子。 如下图所示，决定房屋价格的有很多因素，我们将其进行组合，例如房屋大小和房间数量可以组成 可容纳的家庭人数，邮政编码决定了一个房屋高度步行化的程度，还有地区的富裕程度一起决定了学校的质量，而这些综合起来影响了房屋的价格。 注：高度步行化是指可通过步行在较短的时间内到达目的地，如车站，商场，学校，医院等地。 这样我们就有了一个四个输入的神经网络。 监督学习到目前为止，几乎所有由神经网络创造的经济价值都基于一种机器学习，我们称之为监督学习。这里是监督学习的一些例子。 输入(x) 输出(y) 应用 房屋特征 价格 房地产 广告，用户信息 是否点击广告（0/1） 在线广告 图像 类别（1–1000） 图形分类 音频 文本描述 语音识别 英文 中文 机器翻译 图像，雷达信息 其它车的位置 自动驾驶 神经网络可以处理结构性数据和非结构性数据，下面是一些例子。 为什么深度学习会兴起？深度学习的兴起很大程度上可以说是由规模驱动的。 从上图中可以看出，当数据规模逐渐增大时，传统的机器学习算法的表现保持不变，而神经网络随着规模的增大效果越来越好。在上图的左边，即数据量过小时，此处机器学习算法的优劣很难明确，算法的好坏更取决于手工设计组件的技能，以及算法处理的细节。 神经网络的发展初期是由数据和算力驱动的，但渐渐的，在算法上也出现了很大的创新（很大一部分是加速了计算）。比如说，激活函数 由 sigmoid 函数变成了 ReLU 函数。在 sigmoid 函数的两端，导数趋近于零。如果应用梯度下降算法那么速度将非常慢，而 ReLU 函数就解决了这一问题。","link":"/post/deeplearning-ai-week-1/"},{"title":"深度学习专项课程（3）（第二周）","text":"本周介绍了有关数据不匹配，迁移学习，多任务学习等相关的概念。 数据不匹配数据不匹配问题是指算法擅长处理的数据和你所关心的数据分布不相同的一种情况。比如说，在🐱分类的例子中，你训练所使用的数据是专业的清晰度较高的数据，而在测试时算法所要面对的是用户上传的清晰度并不是很高的图片。 迁移学习神经网络可以从一个任务中习得知识，并将这些知识应用到另一个独立的任务中。举例来说，如果已经训练好了一个网络，可以识别猫这样的对象，然后用习得的知识或部分知识来帮助更好的阅读 x 射线扫描图。这就是所谓的迁移学习。 在下图中，上面部分是识别🐱的神经网络，我们将它的输出层替换掉而前面的隐藏层保留起来，这样就将其应用在了识别 x 射线的扫描图中。 在什么样的条件下应用迁移学习才有意义？ 任务 A 和 B 有相同的输入 任务 A 比 任务 B 有更多的数据 A 的低层的特征可以帮助 学习 B 对于上面的例子来说，识别🐱和识别 x 射线扫描图的输入都是图像，猫的图像数据要远远多于 x 射线扫描图，且识别猫的网络的底层特征有助于识别 x 射线扫描图。 多任务学习多任务学习是指在一个神经网络中我们试图让它同时做几件事。 例如在自动驾驶的场景当中，我们输入一张图片，希望神经网络可以同时识别出行人，红绿灯，指示牌，其他车辆等目标物体。 该例中的神经网络结构如下，前面共用特征，在输出层得出对不同目标的预测。 在什么样的条件下应用多任务学习才有意义？ 底层的共享特征均有助于训练多个任务 通常来说，对于这多个任务它们的数据应该大致相同 训练一个足够大的神经网络能够在所有任务中表现良好","link":"/post/deeplearning-ai-3-week-2/"},{"title":"深度学习专项课程（第三周）","text":"本周课程介绍了浅层神经网络的相关知识 神经网络概览下图中是一个只有一个神经元和三个输入的简单神经网络。 神经元的任务与我们前面所讲的逻辑回归的任务相同，先将输入的特征值加权求和，再加上常数项，在使用 sigmoid 函数（激活函数）求出最后的结果。 我们将多个这样的神经元进行堆叠，这样就得到了一个简单地浅层神经网络。这个神经网络有两层，也就是说要进行两次逻辑回归的运算。 神经网络表示 如图所示，这是一个简单的神经网络，它拥有三层结构。左边的输入特征 x 所在的层我们称之为输入层，中间节点所在的层称之为隐藏层，最右边的叫作输出层。中间层之所以被叫做隐藏层是因为在训练集中，这些中间结点的真正数值我们是不知道的。输入特征本来是用 x 来表示，这里我们用 $a^{[0]}$ 来表示，其中 a 表示 “激活”，它意味着网络中不同层的值将会传递到下一层。右上角的方括号表示这些值来自神经网络的哪一层。有趣的是，在约定俗成的符号约定中，这是一个两层的神经网络,输入层并不计算在内。 计算神经网络的输出 这是单个神经元所进行的计算，与逻辑回归相似。 这是单隐层神经网络中第 [1] 层 4 个节点的计算公式。我们将这些公式以向量化的方式详细的表示出来： $$ \\large z^{[1]} = \\begin{bmatrix} -w_1^{[1]T}- \\\\\\ -w_2^{[1]T}- \\\\\\ -w_3^{[1]T}- \\\\\\ -w_4^{[1]T}- \\end{bmatrix} \\begin{bmatrix} x_1 \\\\\\ x_2 \\\\\\ x_3 \\end{bmatrix} + \\begin{bmatrix} b_1 \\\\\\ b_2 \\\\\\ b_3 \\\\\\ b_4 \\end{bmatrix} = \\begin{bmatrix} w_1^{[1]T}x +b_1 \\\\\\ w_2^{[1]T}x +b_2\\\\\\ w_3^{[1]T}x +b_3\\\\\\ w_4^{[1]T}x +b_4 \\end{bmatrix} = \\begin{bmatrix} z_1^{[1]} \\\\\\ z_2^{[1]} \\\\\\ z_3^{[1]} \\\\\\ z_4^{[1]} \\end{bmatrix} \\\\ a^{[1]} = \\begin{bmatrix} a_1^{[1]} \\\\\\ a_2^{[1]}\\\\\\ a_3^{[1]}\\\\\\ a_4^{[1]} \\end{bmatrix} =\\sigma(z^{[1]}) $$ 下图给出了，第 [1] 层 和第 [2] 层 向量化的计算公式 多个样本的向量化上面一节讲述了单个样本的向量化，这一小节解释了多个样本的向量化。 如果我们使用 for 循环来处理多个训练样本，则速度会非常慢。所以我们需要使用向量化的方法来进行计算。 下面是向量化的表示：我们将所有训练样本 $x^{(i)}$ 进行横向的叠加，同时 $z^{[1] (i)}$ 和 $a^{[1] (i)}$ 也进行横向的叠加。那么在这些矩阵中，横向指标对应了不同的样本，而纵向指标则对应了不同的节点。 下面给出了向量化的计算公式，对于本例中的神经网络，$W^{[1]}$ 是 4x3 的矩阵。 $$\\largeZ^{[1]} = W^{[1]}X + b^{[1]} \\A^{[1]} = \\sigma(Z^{[1]}) \\Z^{[2]} = W^{[1]}X + b^{[2]} \\A^{[2]} = \\sigma(Z^{[2]})$$ 为什么这样的向量化是正确的呢？下图给出了解释，如果你了解线性代数，那么你可以看出这张图片中的解释是正确的，我们用矩阵 $W^{[1]}$ 与各个样本向量相乘，就得到了矩阵 $Z^{[1]}$，为了方便起见，这里省略了 $b^{[1]}$ 这一项。这里只解释了 $Z^{[1]} = W^{[1]}X + b^{[1]}$ 为什么成立，参考这一解释，你可以推导出其他几个式子也是正确的。 激活函数除了常见的 sigmoid 函数以外，激活函数还有其它的几种选择。 上图中第一个就是我们熟悉的 sigmoid 函数，除非在二分类的输出层，不然绝对不要用它作为激活函数。这是因为，tanh 函数，上图右上角所示，几乎在所有场合都更优越。最常用的默认激活函数是 ReLU（修正线性单元）。当你不确定时，最好选择 ReLU。图中最后一个函数我们称为 “带泄露的ReLU” 名称 公式 特点 sigmoid $\\large g(z) = \\frac{1}{1+e^{-z}}$ 除了二分类的输出层，几乎不用 tanh $\\large g(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}$ 几乎在所有场合都优于 sigmoid ReLU $\\large g(z) = max(0,z)$ 当 z 很大时导数不会趋于0而导致速度过慢 带泄露的 ReLU $\\large g(z) = max(0.01z,z)$ 当 z 小于 0 时，导数不是0 为什么一定要用非线性的激活函数呢？如果不使用非线性的激活函数，那么神经网络的运算就只有线性运算。神经网络最后的输出结果只是输入特征的线性组合。这和没有任何隐藏层的标准逻辑回归是一样的，这样就无法学习到更复杂的函数。 激活函数的导数 名称 公式 导数 sigmoid $\\large g(z) = \\frac{1}{1+e^{-z}}$ $\\large g’(z)=\\frac{1}{1+e^{-z}}(1-\\frac{1}{1+e^{-z}})=g(z)(1-g(z))$ tanh $\\large g(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}$ $\\large g’(z)=1-(g(z))^2$ ReLU $\\large g(z) = max(0,z)$ $\\large if\\quad z &gt; 0 \\quad g’(z)=1 \\\\ if\\quad z&lt;0 \\quad g’(z)=0$ 带泄露的 ReLU $\\large g(z) = max(0.01z,z)$ $\\large if\\quad z &gt; 0 \\quad g’(z)=1 \\\\ if\\quad z&lt;0 \\quad g’(z)=0.01$ 神经网络的梯度下降法这里只给出神经网络梯度下降的公式，省略了推导过程。 Forward Propagation$$\\largeZ^{[1]} = W^{[1]}X+b^{[1]} \\\\A^{[1]} = g^{[1]}(Z^{[1]}) \\\\Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]} \\\\A^{[2]} = g^{[2]}(Z^{[2]})$$ Back Propagation$$\\largedZ^{[2]} = A^{[2]} - Y \\\\dW^{[2]} = \\frac{1}{m}dZ^{[2]}A^{[1]T} \\\\db^{[2]} = \\frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)\\\\dZ^{[1]} = W^{[2]T}dZ^{[2]}*g’^{[1]}(Z^{[1]}) \\\\dW^{[1]} = \\frac{1}{m}dZ^{[1]}X^{T}\\\\db^{[1]} = \\frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)$$ 随机初始化在逻辑回归中我们可以初始化参数为 0 ，但在神经网路中我们不这样做。如果我们将神将网络中的节点的参数都初始化为 0， 那么每一个节点都在做同样的运算，它们对下一层的影响也是相同的，所以这样的神经网络是没有意义的。正确的做法是对参数随机初始化，这样可以使每个节点学习到不同的参数。","link":"/post/deeplearning-ai-week-3/"},{"title":"深度学习专项课程（第四周）","text":"本周内容很大一部分与前一周内容重合，重复内容此处不再赘述，这里简单记录新的内容。 为什么使用深层神经网络深度神经网络可以解决很多问题，其实并不需要很大的神经网络，但是需要有深度。深度的神经网络可以学习更复杂的函数。Andrew Ng 在课程中列举了两个例子来解释为什么使用深层神经网络，有兴趣的同学可以参考。 参数与超参数参数$W^{[1]},b^{[1]},W^{[2]},b^{[2]},W^{[3]},b^{[3]}……$ 超参数超参数中的数值需要我们自己设置，而参数 W ，b 的数值将由这些超参数来决定,所以被称为超参数。 学习率 梯度下降法循环的次数 隐层数 隐层节点数 激活函数 ReLU 或 sigmoid 这与大脑有什么关系深度学习和大脑有什么关联性呢？ Andrew Ng 认为关系不大。有时会把深度学习中的神经元和生物中的神经元进行类比，但生物中的神经元到底是如何进行工作的，至今为止神经科学家们都很难解释。所以，目前人们在减少神经网络与人类大脑的对比。","link":"/post/deeplearning-ai-week-4/"},{"title":"机器学习笔记（2）多变量线性回归","text":"本篇介绍了有关在多特征的情况下如何使用线性回归，以及一些相关的技巧。 场景描述在多数时候我们的特征并不会只有一个。在预测房价的例子中，除了房屋的面积之外，房屋的房间数，楼层，房屋的年龄等也可以用于房价的预测。 面积($x_1$) 房间数($x_2$) 楼层($x_3$) 房屋年龄($x_4$) 价格(y) 2101 3 2 20 460 1236 3 1 40 232 1514 2 2 50 315 符号注释 :n : 特征的数量$x^{(i)}$ : 第i个训练样本的特征向量$x^{(i)}_j$ : 第i个训练样本的第j个特征值 例 : $$x^{(2)} = \\begin{bmatrix} 1236 \\\\ 3 \\\\ 1 \\\\ 40 \\end{bmatrix} \\qquad x_3^{(2)} =1$$ 假设函数因为特征的数量增加，假设函数也做出了相应的变化$$h_\\Theta(x) = \\Theta_0 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3 + … + \\Theta_nx_n $$为了书写的方便，我们定义一个$\\quad x_0=1 \\quad$ 即 $(x_0^{(i)}=1)$于是我们有 ：$$h_\\Theta(x) = \\Theta_0x_1 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3 + … + \\Theta_nx_n $$ 为进一步简化这个表达式，我们使用向量的方式来表示 ： $$X=\\begin{bmatrix} x_0\\\\x_1\\\\x_2\\\\x_3\\\\...\\\\x_n \\end{bmatrix} \\qquad \\Theta=\\begin{bmatrix} \\Theta_0\\\\\\Theta_1\\\\\\Theta_2\\\\\\Theta_3\\\\...\\\\\\Theta_n \\end{bmatrix}$$ $$h_\\Theta(x) = \\underbrace{ \\Theta_0x_0 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3 + … + \\Theta_nx_n}_{\\Theta^TX} $$ $$\\Huge\\Downarrow $$ $$h_\\Theta(x) = \\Theta^TX$$ 代价函数$$J(\\Theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\Theta(x^{(i)}) - y^{(i)})$$ 梯度下降 $$Repeat\\left\\{ \\Theta_j = \\Theta_j - \\alpha\\frac{\\partial}{\\partial\\Theta_j}J(\\Theta_0,...,\\Theta_n) \\right\\} $$ 需要注意的是，这里的$\\Theta_j$需要同步更新 同步更新 异步更新 temp0 = $\\alpha\\frac{\\partial}{\\partial\\Theta_0}J(\\Theta_0,…,\\Theta_n)$ temp1 = $\\alpha\\frac{\\partial}{\\partial\\Theta_1}J(\\Theta_0,…,\\Theta_n)$ $\\Theta_0$ = temp0$\\Theta_1$ = temp1 temp0 = $\\alpha\\frac{\\partial}{\\partial\\Theta_0}J(\\Theta_0,…,\\Theta_n)$ $\\Theta_0$ = temp0 temp1 = $\\alpha\\frac{\\partial}{\\partial\\Theta_1}J(\\Theta_0,…,\\Theta_n)$$\\Theta_1$ = temp1 特征缩放(Feature Scaling)确保特征的数值大小在相似的规模下，这样梯度下降法可以更快的收敛。在做特征缩放时并不需要太精确，只是为了使梯度下降法能更快的收敛。 缩放前 缩放后 $x_1 = size(0-2000 feet^2)$ $x_1 = \\frac{size(feet^{2})}{2000} \\,(0\\leq x_1 \\leq 1)$ $x_2=number \\, of \\, bedrooms(1-5)$ $x_1 = \\frac{num \\, of \\, bedrooms}{5} \\,(0\\leq x_2 \\leq 1)$ 均值归一化(Mean normalization)特征缩放的一种方法$$x_1 \\Rightarrow \\frac{x_1 - \\mu_1}{S_1}$$$\\mu_1$ 表示训练集中特征$x_1$的平均值$S_1$ 表示该特征值的范围（max - min） 多项式回归多项式回归就是用线性回归的方式去拟合更复杂的函数，甚至是非线性的函数。 特征选择如图所示，我们有两个特征，房子的临街宽度和垂直深度。但我们通常使用面积来表示房屋的大小。所以我们可以使用房屋的面积（临街宽度 x 垂直深度）作为一个特征。 拟合多项式对于下图中的数据集，我们继续使用一次函数来拟合的话，效果并不太好。如果使用二次函数来拟合的话，效果可能也不是特别好，因为我们知道，二次函数的图像（图中蓝色的线）在后面是一个下降的趋势，然而现实中房价并不会随着房屋面积的增加而减少。所以这里我们可以使用三次函数（图中绿色的线）来拟合。我们只要做一些简单的修改就可以将线性回归应用到多项式上。$$h_\\Theta(x)=\\Theta_0 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3$$$$\\huge\\Downarrow$$$$h_\\Theta(x)=\\Theta_0 + \\Theta_1size + \\Theta_2(size)^2 + \\Theta_3(size)^3\\$$我们令$$x_1=(size)\\ x_2=(size)^2\\ x_3=(size)^3$$即可。需要强调的是，在这种情况下特征缩放就显得尤为重要。 检验方法我们如何判断梯度下降法是否正常工作呢？通常可以观察代价函数的值与迭代次数的关系来判断。当梯度下降法正常运行时，如下图所示，随着迭代次数的增加，代价函数的值越来越小，当梯度下降算法迭代60次左右时，代价函数的值几乎不再变化，说明此时算法已经收敛。当出现以下两种情况时，代价函数的值上下震荡，或是逐渐变大，这都说明梯度下降法并没有正常工作。通常出现这两种情况的原因都是学习率 $\\alpha$ 过大。 学习率选择总的来说学习率过小的话，会导致收敛过慢而学习率过大的话，可能导致无法收敛，代价函数 $J(\\Theta)$ 并不会在每次迭代之后都下降。我们可以通过多次试验的方式找出合适的学习率值的大小。另：按照吴恩达老师的推荐，我们可以如下依次选择学习率的大小。… 0.001，0.03，0.1，0.3 … 正规方程正规方程可以让我们再某些情况下，更快的求解出参数 $\\Theta$。假设我们有m个样本，$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(n)},y^{(n)})$ ,n 个特征。我们将单个样本的特征写成向量形式，再将所有的向量转置后，写成矩阵形式。 $$ x_{(i)} = \\begin{bmatrix} x_0^{(i)} \\\\ x_1^{(i)} \\\\ x_3^{(i)} \\\\ ... \\\\ x_n^{(i)} \\end{bmatrix} \\qquad X = \\underbrace{\\begin{bmatrix} ---(x^{(1)})^T---\\\\ ---(x^{(2)})^T---\\\\ ---(x^{(3)})^T---\\\\ ---------\\\\ ---(x^{(m)})^T---\\\\ \\end{bmatrix}}_{m * (n+1)} $$ 接着，只要求解如下这个矩阵表达式，就可得到参数$\\Theta$的值$$\\Theta = (X^TX)^{-1}X^Ty$$在上式中需要对矩阵求逆，那么如果矩阵不可逆呢？一般来说，大部分矩阵都是可逆的，出现了以下两种情况时，会导致矩阵不可逆: 多余特征如下所示，显然$x_1$和$x_2$两个特征是线性相关的，那么这时就会导致矩阵不可逆$$x_1 = size \\ in \\ feet^2 \\ x_2 = size \\ in \\ m^2$$ 太多特征如果我们的特征数量较多，而样本数量较少，造成特征数量大于样本数量，这种情况下也会导致矩阵不可逆。例如，生物信息学的基因芯片数据中常有成千上万个属性，但往往只有几十，上百个样例。 正规方程与梯度下降法比较 梯度下降 正规方程 缺点 需要多次迭代 需要选择学习率 优点 不需要多次迭代 不需要选择学习率 优点 当特征数量n很大时，也能运行的很好 缺点 当特征数量n较大时，速度很慢 吴恩达老师推荐，当n大于10000时选择梯度下降法，小于10000时选择正规方程法。","link":"/post/machine-learning-AndrewNg-multivariate-linear-regression.md/"},{"title":"机器学习笔记（4）正则化","text":"正则化是解决过拟合问题的一种有效手段。 过拟合定义：如果我们有太多的特征，这时训练出的假设能很好地拟合训练集（代价函数的值约等于0），当不能很好地泛化到新的样本中。泛化是指一个假设模型应用到新样本的能力。 解决过拟合 减少特征的数量 人工选择需要保留的特征 模型选择算法 正则化 保留所有特征，减小参数$\\theta$的值 当我们有很多特征，且或多或少都对预测 y 有影响，正则化也可以工作的很好 正则化 我们给代价函数新增了两项，并给 $\\theta_3$ 和 $\\theta_4$加上很大的系数，这样为了让代价函数的值最小，$\\theta_3$ 和 $\\theta_4$的值就会趋近与 0。最后的效果就好像我们在假设函数中直接去掉了这两项一样。 $$\\Large Features:x_1,x_2,…,x_{100} $$$$\\Large Parameters:\\theta_0,\\theta_1,\\theta_2,…,\\theta_{100}$$事实上，我们的问题中可能会有很多特征，但事先我们不知道该选择哪一个来缩小它们的值，所以我们需要缩小所有的值。如此，代价函数需要作出这样的修改：$$\\Large J(\\Theta)=\\frac{1}{2m}\\Huge[\\Large\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}+\\lambda\\sum_{i=2}^m\\theta_j^2\\Huge]$$其中 $\\lambda\\sum_{i=2}^m\\theta_j^2$ 是正则项，$\\lambda$ 是正则化参数。 当我们的正则化参数 $\\lambda$ 设置的过大时，可能会造成欠拟合的情况。因为此时的参数 $\\theta_j$ 都已经趋近于 0。 线性回归的正则化梯度下降 $$ \\Large repeat\\left\\{ \\begin{aligned} \\Theta_0 = \\Theta_0-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_0^{(i)} \\qquad \\qquad\\\\ \\Theta_j = \\Theta_j-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_j^{(i)} +\\frac{\\lambda}{m}\\theta_j , j\\not ={0} \\end{aligned} \\right\\} $$ 这里我们的 $\\theta_0$ 并不需要正则化。 正规方程 $$\\large X = \\underbrace{\\begin{bmatrix} (x^{(1)})^T\\\\ (x^{(2)})^T\\\\ (x^{(3)})^T\\\\ ....\\\\ (x^{(m)})^T\\\\ \\end{bmatrix}}_{m * (n+1)} \\qquad y = \\begin{bmatrix} y^{(0)} \\\\ y^{(1)} \\\\ y^{(2)} \\\\ ... \\\\ y^{(3)} \\end{bmatrix} \\qquad $$ 这时原来的方程$$\\large\\Theta = (X^TX)^{-1}X^Ty$$我们为其添加新的一项$$\\large \\Theta = (X^TX \\qquad\\underbrace{\\lambda\\begin{bmatrix}0 &amp; … &amp; 0 \\… &amp; 1 &amp; … \\0 &amp; … &amp; 1 \\\\end{bmatrix}}_{(n+1)*(n+1)})^{-1}X^Ty$$这样就实现了正规方程的正则化。By the way，当 $\\lambda$ 大于0时，括号内的矩阵肯定是可逆的。 逻辑回归的正则化代价函数在逻辑回归中代价函数也做了相应的变化 $$ \\large J(\\theta) = \\Huge[ \\large -\\frac{1}{m}\\sum_{i=1}^m y^{(i)}log(h_\\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\\theta(x^{(i)})) \\Huge]\\large + \\frac{\\lambda}{2m}\\sum_{j=1}^n\\theta_j^2 $$ 梯度下降 $$ \\Large repeat\\left\\{ \\begin{aligned} \\Theta_0 = \\Theta_0-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_0^{(i)} \\qquad \\qquad\\\\ \\Theta_j = \\Theta_j-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_j^{(i)} +\\frac{\\lambda}{m}\\theta_j , j\\not ={0} \\end{aligned} \\right\\} $$","link":"/post/machine-learning-AndrewNg-regularization/"},{"title":"机器学习笔记（1）单变量线性回归","text":"机器学习中一种经典的算法 场景描述我们有关于房屋面积和房屋价格的数据集，现在想拟合一条直线通过房屋的面积来预测房屋价格。这条直线应该尽可能的符合已有的数据。 概念介绍假设函数这里我们简单的假设该直线的方程为 $$h(x) = \\Theta x$$ 其中x表示房屋的面积，h(x) 表示预测出的房价。有了这个假设函数我们就可以预测房价了。那么参数$\\Theta$应该怎么确定呢？这里我们需要用到代价函数。 代价函数这里先给出代价函数的表达式$$J(\\Theta)=\\frac{1}{2m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$ 其中 ${x}^{(i)}$表示第i个数据样本中房屋的面积 ${h_\\Theta}({x}^{(i)})$表示使用假设函数预测房屋面积${x}^{(i)}$的得到的房屋价格 ${y}^{(i)}$表示真实的房屋价格 这里我们选择使用均方误差作为衡量预测结果与真实值的偏差。最前面的 $\\frac{1}{2}$ 只是为了计算方便无需在意。 我们所要做的就是改变$\\Theta$的值，使得代价函数J$(\\Theta)$的值最小,当找到一个$\\Theta$使得代价函数的值最小时，我们就确定了参数$\\Theta$。即我们的优化目标：$$minimizeJ(\\Theta)$$ 为什么说我们要找的$\\Theta$会使代价函数取得最小值呢？接下来举例说明。 代价函数详解代价函数与参数$\\Theta$的关系假设我们的数据集中有三个样本点 (1,1) , (2,2) , (3,3)我们可以使用无数条直线来拟合这些样本，但很显然只有当 $\\Theta = 1$时，即 $y=x$ 这条直线有最好预测效果。然后我们将不同的$\\Theta$值带入代价函数，计算其结果： 从图像上可知，当代价函数的图像在最低点时，对应$\\Theta$的值，就是最佳的结果。 通过这个例子不难发现，只要我们求出代价函数的最小值，就可找到我们想要的参数$\\Theta$的值。 那么代价函数的最小值应该怎么求呢？在数学上有许多方法可以解决这个问题，这里我们使用梯度下降法来求代价函数的最小值。 梯度下降法下图是使用梯度下降法求解$\\Theta$的步骤，开始时我们随机赋给$\\Theta$一个初值，重复执行下面的步骤更新$\\Theta$的值。执行一定次数，当$\\Theta$的值基本不再变化时，我们就求出了$\\Theta$的最后结果。 $$\\Theta = \\Theta - \\alpha\\frac{\\partial{J(\\Theta)}}{\\partial\\Theta}$$ 其中关键的步骤是对代价函数求$\\Theta$的偏导，这可以理解为在求某一点的斜率。 当$\\Theta$的值大于最终结果时，$\\Theta$的取值在最终结果的右边，对应点的斜率大于0，即求出的偏导值大于0， $\\Theta$减去一个大于0的数变小。 当$\\Theta$的值小于最终结果时，$\\Theta$的取值在最终结果的左边，对应点的斜率小于0，即求出的偏导值小于0， $\\Theta$减去一个小于0的数后变大。 当$\\Theta$的值越接近最终结果时，导数越接近0，$\\Theta$变化的速度也越慢。 其中 $\\alpha$ 是学习率，它的大小会改变$\\Theta$的改变速度，但取值不能太大，否则会造成$\\Theta$无法收敛。","link":"/post/machine-learning-AndrewNg-univariate-linear-regression/"},{"title":"机器学习（吴恩达）作业（1）","text":"单变量线性回归在这部分的练习中，你将使用单变量的线性回归来预测食品卡车的利润。假设你是a公司的CEO并正在考虑在不同的城市开设一家连锁餐厅。该连锁店已经在多个城市拥有卡车，并且你拥有有关城市的人口和利润的数据。你可以使用这些数据来帮助你选择接下来在那个城市发展。文件ex1data1.txt包含了线性回归问题的数据集，其中第一列是城市人口，第二列是食品卡车在该城市的利润。 绘制数据图像再开始任务之前，我们通过数据可视化来更好的理解数据。因为这个数据集只有两个属性，所以我们可以使用散点图来进行可视化。（我们在现实生活中遇到的很多问题往往是多维的，不能进行二维的绘制） 首先要载入数据,载入数据后我们将其打印在屏幕上1234567print(\"loading data ex1data1.txt...\")ex1data = loadtData('ex1data1.txt')X = ex1data[0]y = ex1data[1]print(X)print(y)print() loadData 函数实现1234567891011121314# 载入数据，返回一个二维的numpy数组，# 第一维是 x轴数据，第二维是 y轴数据def loadtData(file_path): X = np.array([]) Y = np.array([]) for i in open(file_path): # 根据逗号的位置取出数据 x = i[0:i.index(',')-1] y = i[i.index(',')+1:len(i)-1] # 读出的数据是字符串类型，需要转换为浮点类型 X = np.append(X,float(x)) Y = np.append(Y,float(y)) return np.array([X,Y]) 绘制图像接下来我们调用plotData 函数来绘制散点图，顺便设置一下横纵坐标的标题1234x_label = \"Population of City in 10,000s\"#设置横纵坐标的标题y_label = \"Profit in $10,000s\"plotData(X,y,x_label,y_label) plotData函数实现 123456# 将数据可视化,使用散点图def plotData(X,y,x_label,y_label): plt.scatter(X,y) plt.xlabel(x_label) plt.ylabel(y_label) plt.show() 绘制出来的结果应该与下图类似 梯度下降在这一部分，你将使用梯度下降法来拟合单变量线性回归中的参数$\\theta$,使其与我们的数据集相符 更新方程线性回归的目标是使代价函数达到最小值$$J(\\Theta)=\\frac{1}{2m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$假设函数使用下面的线性模型$$h_\\theta(x) = \\theta^Tx = \\theta_0 +\\theta_1x_1$$重新计算模型中参数$\\theta$的值，通过调整参数的值使代价函数的值最小化。我们使用批次梯度下降法来达到目的。在梯度下降法中，每一次迭代都会完成一次更新$$\\theta_j = \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$需要注意的是，所有的$\\theta_j$需要同时更新。梯度下降的每一次更新都会使参数$\\theta_j$更接近最优的值，同时这也会使代价函数的值达到最小。 实现在上面的步骤中，我们已经准备好了线性回归所需的数据。接着，我们给数据增加一个维度，方便我们对参数$\\theta_0$进行优化。我们将参数$\\theta$都初始化为0，并设置学习率为0.01。 123456m = len(y)#样本数量X = np.c_[np.ones(m),X]#为X增加一行 值为1theta = np.zeros((2,1),float)#初始化参数theta#一些梯度下降的设置iterations = 1500 #迭代次数alpha = 0.01 #学习率 计算代价函数当我们使用梯度下降法来最小化代价函数的值时，我们可以通过计算代价函数的值来判断是否收敛。我们接下来的任务就是实现computeCost()函数，该函数的功能就是计算代价函数的值。当我们在实现该函数的时候，需要注意变量X，y是矩阵类型的变量，而不是标量。矩阵的行代表了训练集中的样本。一旦你实现了这个函数，我们就使用初始化为0的参数$\\theta$来运行一次该函数。该函数的运行结果应该是32.07 12345678910111213# 计算并显示初始的代价值J = computeCost(X,y,theta)print('With theta = [0 ; 0] ');print(\"Cost computed = %f \\n\" % J)print('Expected cost value (approx) 32.07\\n');# 继续测试代价函数theta[0] = -1theta[1] = 2J = computeCost(X, y, theta);print('\\nWith theta = [-1 ; 2]\\nCost computed = %f\\n'% J);print('Expected cost value (approx) 54.24\\n'); computeCost函数实现 123456789# 计算代价函数def computeCost(X,y,theta): m = len(y) result = np.dot(X , theta) result = result - y.reshape(97,1) result = np.square(result) result = np.sum( result,axis=0) result = result/(2.0*float(m)) return result 梯度下降接下来你要完成梯度下降的编码。在你的程序中，你要清楚的理解优化目标是什么，什么是需要更新的。你要记住，代价函数的参数是向量$\\theta$,而不是X，y。也就是说，我们需要更新向量$\\theta$的值来是代价函数最小化，而不是改变 X 或 y。如果你不确定的话，参考上面给出的方程，或是视频的课程。我们可以通过观察代价函数的值在每一次更新中是否持续下降，以此来判断梯度下降法是否正常工作。梯度下降在每一次迭代中都会调用computeCost函数，如果你正确实现了computeCost函数和梯度下降，那么你的代价函数的值绝不会增加，并且将会在算法的最后达到一个稳定的值。 123456789print('\\nRunning Gradient Descent ...\\n')# 运行梯度下降theta = gradientDescent(X, y, theta, alpha, iterations);# 将theta的值打印到屏幕上print('Theta found by gradient descent:\\n');print('theta_0 : %f \\ntheta_1 : %f'%(theta[0],theta[1])) ;print('Expected theta values (approx)\\n');print(' -3.6303\\n 1.1664\\n\\n'); gradientDescent 函数实现 123456789101112131415161718# 梯度下降def gradientDescent(X, y, theta, alpha, iterations): m = len(y) for i in range(0,iterations): theta_0 = theta[0] - alpha * computePartialDerivative(X,y,theta,0) theta_1 = theta[1] - alpha * computePartialDerivative(X,y,theta,1) theta[0] = theta_0 theta[1] = theta_1 print( \"iterations : \",i, \" cost : \",computeCost(X,y,theta)) return theta# 计算偏导数def computePartialDerivative(X , y, theta , num): m = len(y) result = 0 for i in range(0,m): result += (theta[0]*X[i][0] + theta[1]*X[i][1] - y[i])*X[i][num] result /= m return result 当你完成了以上任务时，使用最后得到的参数$\\theta$的值来绘制假设函数的图像，你会看到与下面类似的图 1234# 绘制线性拟合的图plt.plot(X[:,1],np.dot(X,theta))plt.scatter(X[:,1],y,c='r')plt.show() 可视化 J($\\theta$)为了更好的理解代价函数 J($\\theta$) , 我们可以将$\\theta_0$和$\\theta_1$的值绘制在二维的网格上。绘图代码 12345678910111213141516171819# 绘制三维的图像fig = plt.figure()axes3d = Axes3D(fig)# 指定参数的区间theta0_vals = np.linspace(-10, 10, 100)theta1_vals = np.linspace(-1, 4, 100)# 存储代价函数值的变量初始化J_vals = np.zeros((len(theta0_vals), len(theta1_vals)))# 为代价函数的变量赋值for i in range(0,len(theta0_vals)): for j in range(0,len(theta1_vals)): t = np.zeros((2,1)) t[0] = theta0_vals[i] t[1] = theta1_vals[j] J_vals[i,j] = computeCost(X, y, t)# 下面这句代码不可少，matplotlib还不熟悉，后面填坑theta0_vals, theta1_vals = np.meshgrid(theta0_vals, theta1_vals) #必须加上这段代码axes3d.plot_surface(theta0_vals,theta1_vals,J_vals, rstride=1, cstride=1, cmap='rainbow')plt.show() 完整代码最后附上完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3D# 载入数据，返回一个二维的numpy数组，# 第一维是 x轴数据，第二维是 y轴数据def loadtData(file_path): X = np.array([]) Y = np.array([]) for i in open(file_path): # 根据逗号的位置取出数据 x = i[0:i.index(',')-1] y = i[i.index(',')+1:len(i)-1] # 读出的数据是字符串类型，需要转换为浮点类型 X = np.append(X,float(x)) Y = np.append(Y,float(y)) return np.array([X,Y])# 将数据可视化,使用散点图def plotData(X,y,x_label,y_label): plt.scatter(X,y) plt.xlabel(x_label) plt.ylabel(y_label) plt.show()# 计算代价函数def computeCost(X,y,theta): m = len(y) result = np.dot(X , theta) result = result - y.reshape(97,1) result = np.square(result) result = np.sum( result,axis=0) result = result/(2.0*float(m)) return result# 梯度下降def gradientDescent(X, y, theta, alpha, iterations): m = len(y) for i in range(0,iterations): theta_0 = theta[0] - alpha * computePartialDerivative(X,y,theta,0) theta_1 = theta[1] - alpha * computePartialDerivative(X,y,theta,1) theta[0] = theta_0 theta[1] = theta_1 print( \"iterations : \",i, \" cost : \",computeCost(X,y,theta)) return theta# 计算偏导数def computePartialDerivative(X , y, theta , num): m = len(y) result = 0 for i in range(0,m): result += (theta[0]*X[i][0] + theta[1]*X[i][1] - y[i])*X[i][num] result /= m return result#======================== 绘图 ====================================print(\"loading data ex1data1.txt...\")ex1data = loadtData('ex1data1.txt')X = ex1data[0]y = ex1data[1]print(X)print(y)print()x_label = \"Population of City in 10,000s\"#设置横纵坐标的标题y_label = \"Profit in $10,000s\"#绘图plotData(X,y,x_label,y_label)#======================= 代价函数 和 梯度下降 ======================m = len(y)#样本数量X = np.c_[np.ones(m),X]#为X增加一行 值为1theta = np.zeros((2,1),float)#初始化参数theta#一些梯度下降的设置iterations = 1500 #迭代次数alpha = 0.01 #学习率print(\"Testing the coust function ...\\n\")# 计算并显示初始的代价值J = computeCost(X,y,theta)print('With theta = [0 ; 0] ');print(\"Cost computed = %f \\n\" % J)print('Expected cost value (approx) 32.07\\n');# 继续测试代价函数theta[0] = -1theta[1] = 2J = computeCost(X, y, theta);print('\\nWith theta = [-1 ; 2]\\nCost computed = %f\\n'% J);print('Expected cost value (approx) 54.24\\n');print('\\nRunning Gradient Descent ...\\n')# 运行梯度下降theta = gradientDescent(X, y, theta, alpha, iterations);# 将theta的值打印到屏幕上print('Theta found by gradient descent:\\n');print('theta_0 : %f \\ntheta_1 : %f'%(theta[0],theta[1])) ;print('Expected theta values (approx)\\n');print(' -3.6303\\n 1.1664\\n\\n');# 绘制线性拟合的图plt.plot(X[:,1],np.dot(X,theta))plt.scatter(X[:,1],y,c='r')plt.show()# 绘制三维的图像fig = plt.figure()axes3d = Axes3D(fig)# 指定参数的区间theta0_vals = np.linspace(-10, 10, 100)theta1_vals = np.linspace(-1, 4, 100)# 存储代价函数值的变量初始化J_vals = np.zeros((len(theta0_vals), len(theta1_vals)))# 为代价函数的变量赋值for i in range(0,len(theta0_vals)): for j in range(0,len(theta1_vals)): t = np.zeros((2,1)) t[0] = theta0_vals[i] t[1] = theta1_vals[j] J_vals[i,j] = computeCost(X, y, t)# 下面这句代码不可少，matplotlib还不熟悉，后面填坑theta0_vals, theta1_vals = np.meshgrid(theta0_vals, theta1_vals) #必须加上这段代码axes3d.plot_surface(theta0_vals,theta1_vals,J_vals, rstride=1, cstride=1, cmap='rainbow')plt.show()","link":"/post/machine-learning-AndrewNg-ex1/"},{"title":"机器学习（吴恩达）作业（2）","text":"在这个练习中，我们将实现逻辑回归算法，并将它应用到两个不同的数据集中。 逻辑回归在这部分的练习中，你将创建一个逻辑回归的模型去预测某个学生能否进入大学。假定你是大学招生办的主任，你想要通过两次测验的结果来决定申请人是否能获得入学资格。 你已经有了前面的申请人的历史数据，你可以将它作为逻辑回归的训练集数据。每一个训练样本中包括申请人两次测验的分数和是否获得了入学资格。 你的任务是建立一个分类模型使用申请人在两次测验的分数给出其能否入学的可能性。 可视化数据如果可以的话，在实现任何学习算法之前先对数据进行可视化。我们需要实现 plotData 函数来载入数据并将其可视化。最后的结果应该如下图所示，两个坐标轴是两次测验的分数，并且正例和反例应该用不同的标记符号。 实现代码 123456789101112131415161718192021222324252627282930313233def loadData(file_path): count = len(open(file_path,'rU').readlines()) data = np.zeros(shape=(count,3),dtype=float) index = 0 for row in open(file_path): # 根据逗号的位置取出数据 # 读出的数据为字符串格式，需要转换为float格式 s1 = float(row[0:row.index(',')-1]) s2 = float(row[row.index(',')+1:len(row)-3]) label = int( row[len(row)-2]) data[index][0] = s1 data[index][1] = s2 data[index][2] = label index+=1 return datadef plotData(data,x_label,y_label): # 根据第三列的数据分为两部分显示 data_0 = data[data[:,2]==0] data_1 = data[data[:,2]==1] X_0 = data_0[:,0] y_0 = data_0[:,1] X_1 = data_1[:,0] y_1 = data_1[:,1] fig = plt.figure() plt.scatter(X_0,y_0,marker='o') plt.scatter(X_1,y_1,marker='v') plt.xlabel(x_label) plt.ylabel(y_label) plt.show() 实现sigmoid函数当你在开始实现代价函数之前，回忆一下逻辑回归的假设函数： $$\\large h_\\theta(x)=g(\\theta^TX)$$其中 g 函数 就是 sigmoid 函数，sigmoid 函数的定义：$$\\large g(z) = \\frac{1}{1+e^{-z}}$$ 你的第一步是实现 sigmoid 函数，当你完成编码之后，最好测试一下你实现的 sigmoid 函数。当你使用很大的整数来测试时，返回的值应该趋向于 1 ，使用很大的负数时，返回的值应该趋向于 0 。使用 0 来测试时，得到的值应该是 0.5 。你实现的函数应该也可以适用于向量和矩阵。对于矩阵类型的参数，你的函数应该对矩阵中的每一个值进行计算。 1234# simgoid 函数def sigmoid(z): z=1/(1+np.exp(-z)) return z 代价函数和梯度现在你将实现代价函数和梯度的计算。逻辑回归中的代价函数： $$ \\large J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m[-y^{(i)}log(h_\\theta(x^{(i)}))-(1-y^{(i)})log(1-h_\\theta(x^{(i)}))] $$ 代价的梯度是一个与参数 $\\theta$ 有着同样长度的向量，第 j 个元素的定义如下： $$ \\large \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}x_j^{(i)} $$ 需要注意的是，梯度的公式看起来与线性回归的公式是相同的，但因为假设函数的不同其实质是不同的。当你实现 costFunction 函数之后使用初值为0的参数$\\theta$计算初始的代价值,得到的结果应该是 0.693 12345678910111213# 代价函数def costFunction(theta, X, y): m=X.shape[0] J = (-np.dot(y.T, np.log(sigmoid(X.dot(theta)))) - \\ np.dot((1 - y).T, np.log(1 - sigmoid(X.dot(theta))))) / m return J# 梯度def gradient(theta,X,y): m,n=X.shape theta=theta.reshape((n,1)) grad=np.dot(X.T,sigmoid(X.dot(theta))-y)/m return grad.flatten() 学习参数原作业中使用 octave 的 fminunc 函数来优化参数 $\\theta$ , 这里我们使用 python scipy 库中的 optimize 函数来优化。 在这个函数中会调用你写好的 costFunction 函数来优化参数，optimize 函数给出的最后结果应该是：cost 约等于 0.203。最后得到的 $\\theta$ 值将会用来绘制决策边界，如下图所示： 12345import scipy.optimize as opresult = op.minimize(fun=costFunction, x0=initial_theta, args=(X, y), method='TNC', jac=gradient)cost = result.funtheta = result.x 评估逻辑回归在学习参数之后，你可以使用这个模型去预测一个学生能否获得入学资格。如果一个学生测试1的分数为45，而测试而的分数为85，那么他获得入学资格的可能性应该为 0.776。另一个评估我们得到的参数的方式是模型在训练集上预测的结果如何。这里我们需要实现 predict 函数。如果一切正常的话，我们得到的在训练集上的准确率是0.89。 1234567891011# 预测函数def predict(theta,X): p = sigmoid(X.dot(theta)) p = np.where(p &gt; 0.5,1,0) p = p.reshape(len(p),1) return p# Compute accuracy on our training setp = predict(theta, X) print('Train Accuracy: ', np.mean(p == y) * 100)print('Expected accuracy (approx): 89.0') 正则化逻辑回归在这部分的练习中，你将实现正则化的逻辑回归算法，并用它去预测制造工厂生产的芯片能否通过质量保证（QA）。在 QA 中，一块芯片需要通过多个测试以确保它能够正常工作。假设你是工厂的产品经理，并且你有了一些芯片在两种不同测试中的结果。你将根据测试的结果来判断是否应该接受这批产品。为了帮助你做出决定，你可以使用过去的芯片的测试结果来建立一个逻辑回归模型。 可视化数据与前面的练习相似，使用 plotdata 函数是数据可视化，如下图所示，坐标轴是两次测试的分数，正例（y = 1 ， 接受），反例（y = 0，拒绝）样本使用不同的符号显示。 从上图中我们可以知道，我们的数据集中的正例和反例不能使用直线来分割。直接将逻辑回归应用在这个数据集中效果可能并不好，因为常规的逻辑回归只能得到线性的决策边界。 特征映射通过每个数据点来创造更多的特征可以更好的适应数据。在函数 mapFeature 中，我们将 x1 和 x2 映射到所有的 6 次多项式。 $$mapFeature(x) = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_1^2 \\\\ x_1x_2 \\\\ x_2^2 \\\\ x_1^3 \\\\ …\\\\ x_1x_2^5 \\\\ x_2^6\\end{bmatrix}$$ 我们将两个特征（在两个 QA 测试中的分数）转换成了 28 维的向量。一个逻辑回归的分类器在这样的高维向量上训练会得到更复杂的决策边界，当在 2 维的图像上绘制时，会呈现出非线性。尽管特征映射可以使我们构建出更有表现力的分类器，但同时它也更容易过拟合。在下一部分的联系中你将实现正则化的逻辑回归，同时你也可以看到正则化是如何作用在过拟合问题上的。 1234567def mapFeature(X1,X2): degree = 6 out = np.ones(X1.shape) for i in range(1,degree + 1): for j in range(0,i+1): out = np.c_[out,np.power(X1,i-j)*np.power(X2,j)] return out 代价函数和梯度现在你将编码实现计算正则化逻辑回归的代价函数和梯度。回忆一下逻辑回归中正则化的代价函数。 $$ \\large J(\\theta) = \\Huge[ \\large -\\frac{1}{m}\\sum_{i=1}^m y^{(i)}log(h_\\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\\theta(x^{(i)})) \\Huge]\\large + \\frac{\\lambda}{2m}\\sum_{j=1}^n\\theta_j^2 $$ 注意你无需正则化参数 $\\theta_0$。代价函数的梯度是一个向量，定义如下： $$ \\large \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\qquad \\qquad for \\qquad j = 0 \\\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = (\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}) +\\frac{\\lambda}{m}\\theta_j \\qquad \\qquad for \\qquad j\\not ={0} $$ 当你完成函数 costFunctionReg 时，使用初始化为 0 的参数 $\\theta$ 得到的结果应该是0.693。 123456789101112131415161718def costFunctionReg(theta, X, y, my_lambda): m = len(X) h = sigmoid(X.dot(theta)) J = (-1/m)*(( y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h))) ) \\ + my_lambda/(2*m) *(np.sum(np.square(theta),axis=0)) return J# 梯度def gradient(theta,X,y,my_lambda): grad = np.zeros(theta.shape) for j in range(0,len(grad)): h = sigmoid(X.dot(theta)) if j == 0 : grad[j] = (1/m) * np.sum((h-y)*X[:,j],axis=0) else : grad[j] = (1/m) * np.sum((h-y)*X[:,j],axis=0) + my_lambda/m*theta[j] return grad 学习参数与前面的部分相似，这里我们使用 python scipy 库中的 optimize 函数来优化。 123result = op.minimize(fun=costFunctionReg, x0=initial_theta, args=(X, y,my_lambda), method='TNC', jac=gradient)cost = result.funtheta = result.x 绘制决策边界参数 lambda 的不同，会影响最后模型的结果，我们来观察一下。 lambda = 0的时候,从下图中可以看到，这时相当于不进行正则化，已经出现了过拟合的情况， Train Accuracy: 87.28813559322035lambda = 1，此时的效果是最好的， Train Accuracy: 83.05084745762711lambda = 10，此时的 Train Accuracy: 74.57627118644068lambda = 100,此时的 Train Accuracy: 60.16949152542372 123456789101112131415161718192021222324252627282930313233343536# 绘制决策边界def plotDecisionBoundary(theta,X,y,data): # 根据第三列的数据分为两部分显示 data_0 = data[data[:,2]==0] data_1 = data[data[:,2]==1] X_0 = data_0[:,0] y_0 = data_0[:,1] X_1 = data_1[:,0] y_1 = data_1[:,1] fig = plt.figure() plt.scatter(X_0,y_0,marker='o',label='y = 0') plt.scatter(X_1,y_1,marker='v',label='y = 1') # Here is the grid range u = np.linspace(-1, 1.5, 50) v = np.linspace(-1, 1.5, 50) z = np.zeros((u.size, v.size)) # Evaluate z = theta*x over the grid for i in range(0, u.size): for j in range(0, v.size): z[i, j] = np.dot(mapFeature(u[i], v[j]), theta) z = z.T # Plot z = 0 # Notice you need to specify the range [0, 0] cs = plt.contour(u, v, z, levels=[0], colors='r', label='Decision Boundary') plt.legend([cs.collections[0]], ['Decision Boundary']) plt.show()","link":"/post/machine-learning-AndrewNg-ex2/"},{"title":"机器学习笔记（3）逻辑回归","text":"在线性回归中我们需要预测的是连续的值，而在逻辑回归中我们需要预测的是离散值。虽然该算法中有“回归”二字，但是做的是分类的问题。 场景描述线性回归有以下的应用场景，例如邮件的过滤，需要判断一封邮件是否是垃圾邮件。又或是肿瘤的诊断，需要判断肿瘤是良性或是恶性等等。 基本概念应该如何构建一个分类算法呢？先来看看将我们前面所学的线性回归直接应用到分类问题中会怎么样。在肿瘤的例子中，我们选择肿瘤的大小这一特征来预测肿瘤是良性还是恶性。 我们这里定义 $y\\in \\left\\{ 0,1 \\right\\}$ , 0 代表良性肿瘤，1 代表恶性肿瘤。下图中我们有几个正例和反例，且我们已经根据样本拟合出了一条假设函数的直线。我们将输出的阈值设为0.5，当假设函数的输出值大于等于0.5时，我们预测 y = 1 ，当输出值小于0.5时我们预测 y = 0。根据这条直线我们可预测当肿瘤的size大于这一点（y=0.5时，直线上的点）时我们预测 y = 1，小于这一点时我们则预测 y = 0。这样看来这个假设函数可以很好的将正负样本区分开来，线性回归在分类的表现上似乎很不错，但是且慢，让我们看下面的例子：这里我们新增加了一个样本点，并且根据这个新的训练集拟合出了一个新的假设函数，该假设函数的图像如上方蓝色直线所示。从这条直线看来，分类的效果并不好，蓝色点左边的预测 y = 0，右边的预测为 y = 1 则它对相当一部分的样本点做出了错误的预测。由此可见线性回归并不适合直接应用到分类的任务中。 逻辑回归模型其实我们稍作修改就可以将线性回归应用到分类问题中。我们需要给定一个新的假设函数，这个新的假设函数输出的值应该在0到1之间（$0\\leq h_\\theta\\leq1$）。下面我们给出新的假设函数的定义：$$\\Large h_\\theta(x)=g(\\Theta^Tx)$$$$\\huge\\qquad\\Downarrow \\normalsize Z=\\Theta X$$$$\\Large h_\\theta(x)=g(Z)=\\frac{1}{1+e^{-Z}}=\\frac{1}{1+e^{-\\Theta X}}$$其中$g(Z) = \\frac{1}{1+e^{-Z}}$是对数几率函数，它单调可微，是一种“Sigmoid 函数”它将Z值转化为一个接近 0 或 1 的 y 值，并且其输出值在 Z = 0 附近变化很陡。注：Sigmoid 函数即形似 S 的函数，对率函数是 Sigmoid 函数最重要的代表 假设函数的解释$h_\\theta(x)=$输入一个 x，给出 y = 1 的概率估计。例：当 $x = \\begin{bmatrix}x_0\\\\ x_1\\end{bmatrix} = \\begin{bmatrix}1\\\\ tumor\\,size\\end{bmatrix}$时，$h_\\theta(x) =0.7$我们可以说，有70%的概率肿瘤是恶性的。 决策边界 从上面 Sigmoid 函数的图像可以看出，当我们将假设函数的阈值设为 0.5 时，Z的值在 0 处便成为了一个分界点。当$h_\\theta \\geq0.5$ , 我们预测 y = 1当$h_\\theta &lt;0.5$ , 我们预测 y = 0即当$Z \\geq 0$ , 我们预测 y = 1当$Z &lt; 0$ , 我们预测 y = 0 假设我们有一个如下图所示的一个训练集 我们有了以下的假设函数，并已经拟合出了参数$\\Theta$$$\\Large h_\\theta(x)=g(\\theta_0+\\theta_1x_1+\\theta_2x_2)$$$$\\Huge\\Downarrow\\normalsize \\Theta=\\begin{bmatrix} -3 \\\\ 1 \\\\ 1 \\end{bmatrix}$$$$\\Large h_\\theta(x)=g(-3+x_1+x_2)$$那么，我们可以预测当 $-3+x_1+x_2\\geq0$时， y = 1当 $-3+x_1+x_2&lt;0 $时， y = 0这里可以看出$x_1+x_2=3$ 可以作为预测的分界线，接着我们在图中做出关于$x_1,x_2$的图像，即图中红色的线。我们将这个线称为“决策边界” 假设函数的不同，得到的决策边界也不尽相同。当假设函数变得复杂时，我们也可以得到非线性的决策边界。比如下面的例子 $$\\Large h_\\theta(x)=g(\\theta_0+\\theta_1x_1+\\theta_2x_2+\\theta_3x_1^2+\\theta_4x_2^2)$$$$\\huge\\Downarrow\\normalsize \\Theta =\\begin{bmatrix}-1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$$$$\\Large h_\\theta(x)=g(-1+x_1^2+x_2^2)$$我们可以得到决策边界 $x_1^2+x_2^2=1$ 当假设函数更复杂的话，我们可以得到更加有趣的决策边界： 需要注意的是，决策边界不是训练集的属性，而是假设函数本身及其参数的属性。只要给定了参数向量$\\Theta$，决策边界就决定了。我们不是用训练集来定义决策边界，而是用训练集来拟合参数$\\Theta$ 代价函数既然我们有了假设函数，那么我们就需要通过代价函数拟合出参数$\\Theta$的值。我们再来回顾一下线性回归的大家函数，并对其的表示方法做一些改进：$$\\Large J(\\Theta)=\\frac{1}{2m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$$$\\Huge\\Downarrow$$$$\\Large J(\\Theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\underbrace{\\frac{1}{2}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}}$$$$\\qquad\\qquad\\qquad\\qquad\\Huge\\Downarrow$$$$\\Large cost(h_\\theta(x),y) = \\frac{1}{2}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$ 如果直接将假设函数带入到这个代价函数中的话，即令$\\Large h_\\theta(x)=\\frac{1}{1+e^{-\\Theta X}}$我们将会得到一个非凸优化问题。而这并不是我们想看到的。所以我们需要一个新的代价函数。 逻辑回归的代价函数 $$ \\Large cost(h_\\theta) =\\left\\{ \\begin{aligned} -log(h_\\theta(x)) \\qquad y=1 \\\\ -log(1-h_\\theta(x)) \\qquad y=0 \\end{aligned} \\right. $$ 为了更加直观的了解逻辑回归的代价函数我们将其的图像画出：当 y = 1 时,从下图中可看出，若$h_\\theta(x)=1$ , cost = 0若$h_\\theta(x)=0$ , cost -&gt; $\\infty$也就是说，当真值为 1 时，而我们很肯定的预测它为 0 ，那么我们就使用很大的代价来“惩罚”这个算法 当 y = 0 时,从下图中可看出，若$h_\\theta(x)=0$ , cost = 0若$h_\\theta(x)=1$ , cost -&gt; $\\infty$ 同样的，当真值为 0 时，而我们很肯定的预测它为 1 ，那么我们就使用很大的代价来“惩罚”这个算法 这样我们就了解了这个代价函数的作用，当这个表示方法并不方便，我们需要根据 y 的值来决定使用哪个表达式。其实我们将其写进一个表达式中：$$\\Large cost(h_\\theta(x),y)=-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x))$$可以验证，这个表达式和原来的表达式是等价的。 我们写出代价函数的完整表达式$$\\Large J(\\theta) = \\frac{1}{m}cost(h_\\theta(x),y)$$$$\\Huge \\Downarrow$$$$\\Large J(\\theta) = -\\frac{1}{m}y^{(i)}log(h_\\theta(x^{(i)}))-(1-y^{(i)})log(1-h_\\theta(x^{(i)}))$$ 梯度下降直接给出梯度下降的公式 $$\\Large repeat\\left\\{\\Theta_j = \\Theta_j-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_j^{(i)} \\right\\}$$ 这里仍需要同时更新所有的$\\Theta_j$认真的读者可以发现，这个梯度下降的公式和线性回归的公式是一样的，但实际上它们并不相同，因为此处的假设函数的定义已经改变了。 优化算法除了梯度下降法之外还需许多别的算法可以用来拟合参数，比如说 Conjugate gradient BFGS L-BFGS 这些算法相比于梯度下降法有如下优点： 无需选择血虚率 比梯度下降法更快 不可避免的也有缺点： 更加复杂难懂 这些算法内有一个智能内循环，称之为线搜索算法，它可以自动尝试不同的学习率，并自动选择一个好的学习率，甚至可以为每次迭代选择不同的学习率。 因为这些算法较复杂，在不了解其细节的情况下使用，可能会使模型的调试更加不透明一些，但在处理大规模的机器学习问题时，仍倾向于使用这些算法，而不是梯度下降算法。 多分类问题上面我们讲的都是二元分类问题，有时我们还会遇到多分元类的问题。如： 邮件分类问题，学习，工作，家庭，朋友等等 病情诊断，健康 感冒 发烧等 天气预测晴天，多云，下雨，下雪等 如图所示，我们的训练集中有三种类别的样本。我们可以为每一种类别构建一个分类器来实现多元分类。 首先我们创建一个新的训练集，将三角形设为正类，其它两类设为负类，根据这个训练集构建一个分类器。其余两类如此构建各自的分类器。 这样我们对每一种类别都有了各自的分类器，当输入新的 X 时，我们用所有的分类器对其进行预测，输出概率最高的一个（$max\\, h(\\theta^i(x)$)），便是最终的结果。 绘图代码最后放上一点绘图的代码 绘制 Sigmoid 函数 123456789101112131415161718192021222324252627282930313233#创建画布fig = plt.figure(figsize=(5, 5))#使用axisartist.Subplot方法创建一个绘图区对象axax = axisartist.Subplot(fig, 111) #将绘图区对象添加到画布中fig.add_axes(ax)# 通过set_visible方法设置绘图区所有坐标轴隐藏ax.axis[:].set_visible(False)# ax.new_floating_axis代表添加新的坐标轴ax.axis[\"x\"] = ax.new_floating_axis(0,0)# 给x坐标轴加上箭头ax.axis[\"x\"].set_axisline_style(\"-&gt;\", size = 1.0)# 添加y坐标轴，且加上箭头ax.axis[\"y\"] = ax.new_floating_axis(1,0)ax.axis[\"y\"].set_axisline_style(\"-|&gt;\", size = 1.0)# 设置x、y轴上刻度显示方向ax.axis[\"x\"].set_axis_direction(\"top\")ax.axis[\"y\"].set_axis_direction(\"right\")# 设置x、y轴标签ax.axis[\"x\"].label.set_text(\"Z\")ax.axis[\"y\"].label.set_text(\"g ( Z )\")# 设置坐标轴范围和标签plt.xlim(-10,10)plt.ylim(0,1)plt.ylabel(\"Z\")# plt.ylabel(\"g(Z)\")z = np.linspace(-10,10,1000)g = 1.0/(1+pow(math.e,-z))plt.plot(z,g) 代价函数的代码 1234567891011121314151617181920212223# cost() = -log(h(x))fig = plt.figure()x = np.linspace(0.0001,1,100)y = -(np.log(x))plt.xlabel(\"h(x)\")plt.xlim(0,1)plt.ylim(0,10)plt.plot(x,y)plt.show()# cost() = -log(1- h(x))fig = plt.figure()x = np.linspace(0,1,1000)y = -(np.log(1-x))plt.xlabel(\"h(x)\")plt.xlim(0,1)plt.ylim(0,10)plt.plot(x,y)plt.show()","link":"/post/machine-learning-AndrewNg-logistic-regression/"}],"tags":[{"name":"深度学习","slug":"深度学习","link":"/tags/深度学习/"},{"name":"Mask R-CNN","slug":"Mask-R-CNN","link":"/tags/Mask-R-CNN/"},{"name":"鸟类识别","slug":"鸟类识别","link":"/tags/鸟类识别/"},{"name":"正则化","slug":"正则化","link":"/tags/正则化/"},{"name":"神经网络","slug":"神经网络","link":"/tags/神经网络/"},{"name":"优化算法","slug":"优化算法","link":"/tags/优化算法/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"迁移学习","slug":"迁移学习","link":"/tags/迁移学习/"},{"name":"正规方程","slug":"正规方程","link":"/tags/正规方程/"},{"name":"线性回归","slug":"线性回归","link":"/tags/线性回归/"},{"name":"作业","slug":"作业","link":"/tags/作业/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"逻辑方程","slug":"逻辑方程","link":"/tags/逻辑方程/"},{"name":"逻辑回归","slug":"逻辑回归","link":"/tags/逻辑回归/"}],"categories":[{"name":"学习","slug":"学习","link":"/categories/学习/"}]}