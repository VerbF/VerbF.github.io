{"pages":[{"title":"about","text":"联系我Email:xixiangshu704@qq.com","link":"/about/index.html"}],"posts":[{"title":"深度学习专项课程（第一周）","text":"“深度学习”指的是训练神经网络，那么神经网络到底是什么呢？ 什么是神经网络我们还是从一个预测的例子开始。我们有关于房屋尺寸和价格的样本集，我们想要通过这个样本来预测房屋的价格。我们可以通过线性回归来解决这个问题。但我们知道房屋的价格不可能为负数，所以我们对这个函数稍作修改，使其不为负数，如下图所示。这个函数我们称为 ReLU（线性整流函数，Rectified Linear Unit, ReLU） 函数 这就可以看做是一个几乎是最简单的神经网络了。 我们把它换一个形式画出来，如下图所示。我们把 房屋面积 size 作为神经网络的输入，中间的圆圈我们将它称为一个独立的神经元，房屋的价格为神经网络的输出。这个神经网络完成了上面图中的功能，神经元的作用就是输入面积，完成线性运算，取不小于 0 的值，最后输出房屋的预测价格。 我们可以将神经元想象成乐高积木，我们将神经元堆叠起来可以形成更大的神经网络。我们来可一个例子。 如下图所示，决定房屋价格的有很多因素，我们将其进行组合，例如房屋大小和房间数量可以组成 可容纳的家庭人数，邮政编码决定了一个房屋高度步行化的程度，还有地区的富裕程度一起决定了学校的质量，而这些综合起来影响了房屋的价格。 注：高度步行化是指可通过步行在较短的时间内到达目的地，如车站，商场，学校，医院等地。 这样我们就有了一个四个输入的神经网络。 监督学习到目前为止，几乎所有由神经网络创造的经济价值都基于一种机器学习，我们称之为监督学习。这里是监督学习的一些例子。 输入(x) 输出(y) 应用 房屋特征 价格 房地产 广告，用户信息 是否点击广告（0/1） 在线广告 图像 类别（1–1000） 图形分类 音频 文本描述 语音识别 英文 中文 机器翻译 图像，雷达信息 其它车的位置 自动驾驶 神经网络可以处理结构性数据和非结构性数据，下面是一些例子。 为什么深度学习会兴起？深度学习的兴起很大程度上可以说是由规模驱动的。 从上图中可以看出，当数据规模逐渐增大时，传统的机器学习算法的表现保持不变，而神经网络随着规模的增大效果越来越好。在上图的左边，即数据量过小时，此处机器学习算法的优劣很难明确，算法的好坏更取决于手工设计组件的技能，以及算法处理的细节。 神经网络的发展初期是由数据和算力驱动的，但渐渐的，在算法上也出现了很大的创新（很大一部分是加速了计算）。比如说，激活函数 由 sigmoid 函数变成了 ReLU 函数。在 sigmoid 函数的两端，导数趋近于零。如果应用梯度下降算法那么速度将非常慢，而 ReLU 函数就解决了这一问题。","link":"/post/deeplearning-ai-week-1/"},{"title":"基于 Mask R-CNN 的鸟类识别 app","text":"一个基于 Mask R-CNN 的鸟类识别 APP，可以识别五种鸟类，mAP 83%。 前言这时博主的毕设的课题，时间紧迫加上自身能力所限，最后的作品还有很多不足，还望各位不吝指正。代码已经上传到了 github,并附上了详细的使用说明。先放一下效果图 概述整个系统包括用户端和服务端两部分。用户端通过 http 协议将待识别的鸟类图片上传到服务端，服务端再将识别后的图片和鸟类信息返回给用户端。 鸟类识别由 Mask R-CNN 框架训练出的模型完成。 鸟类识别博主标注了 5 类，共 300 张鸟类图片，使用 Mask R-CNN 框架进行训练，得到了识别鸟类的模型。 5 种鸟类的图片 平均准确率的统计图 用户端用户端运行在安卓系统上，包括图片的选择，图片的裁剪，图片的上传，以及识别结果的显示等功能。 服务端服务端采用Python编程语言进行编写，服务端完成了接收用户端上传图片，识别图片，从数据库中查询鸟类的信息，将识别的结果回传到用户端等功能。 服务端使用了 flask web 应用框架。执行 server.py 脚本后服务启动，当服务端接收到用户端上传的鸟类图片时将会调用 detect.py 脚本，脚本调用模型对鸟类进行识别。","link":"/post/bird-identification-app/"},{"title":"深度学习专项课程（第三周）","text":"本周课程介绍了浅层神经网络的相关知识 神经网络概览下图中是一个只有一个神经元和三个输入的简单神经网络。 神经元的任务与我们前面所讲的逻辑回归的任务相同，先将输入的特征值加权求和，再加上常数项，在使用 sigmoid 函数（激活函数）求出最后的结果。 我们将多个这样的神经元进行堆叠，这样就得到了一个简单地浅层神经网络。这个神经网络有两层，也就是说要进行两次逻辑回归的运算。 神经网络表示 如图所示，这是一个简单的神经网络，它拥有三层结构。左边的输入特征 x 所在的层我们称之为输入层，中间节点所在的层称之为隐藏层，最右边的叫作输出层。中间层之所以被叫做隐藏层是因为在训练集中，这些中间结点的真正数值我们是不知道的。输入特征本来是用 x 来表示，这里我们用 $a^{[0]}$ 来表示，其中 a 表示 “激活”，它意味着网络中不同层的值将会传递到下一层。右上角的方括号表示这些值来自神经网络的哪一层。有趣的是，在约定俗成的符号约定中，这是一个两层的神经网络,输入层并不计算在内。 计算神经网络的输出 这是单个神经元所进行的计算，与逻辑回归相似。 这是单隐层神经网络中第 [1] 层 4 个节点的计算公式。我们将这些公式以向量化的方式详细的表示出来： $$ \\large z^{[1]} = \\begin{bmatrix} -w_1^{[1]T}- \\\\\\ -w_2^{[1]T}- \\\\\\ -w_3^{[1]T}- \\\\\\ -w_4^{[1]T}- \\end{bmatrix} \\begin{bmatrix} x_1 \\\\\\ x_2 \\\\\\ x_3 \\end{bmatrix} + \\begin{bmatrix} b_1 \\\\\\ b_2 \\\\\\ b_3 \\\\\\ b_4 \\end{bmatrix} = \\begin{bmatrix} w_1^{[1]T}x +b_1 \\\\\\ w_2^{[1]T}x +b_2\\\\\\ w_3^{[1]T}x +b_3\\\\\\ w_4^{[1]T}x +b_4 \\end{bmatrix} = \\begin{bmatrix} z_1^{[1]} \\\\\\ z_2^{[1]} \\\\\\ z_3^{[1]} \\\\\\ z_4^{[1]} \\end{bmatrix} \\\\ a^{[1]} = \\begin{bmatrix} a_1^{[1]} \\\\\\ a_2^{[1]}\\\\\\ a_3^{[1]}\\\\\\ a_4^{[1]} \\end{bmatrix} =\\sigma(z^{[1]}) $$ 下图给出了，第 [1] 层 和第 [2] 层 向量化的计算公式 多个样本的向量化上面一节讲述了单个样本的向量化，这一小节解释了多个样本的向量化。 如果我们使用 for 循环来处理多个训练样本，则速度会非常慢。所以我们需要使用向量化的方法来进行计算。 下面是向量化的表示：我们将所有训练样本 $x^{(i)}$ 进行横向的叠加，同时 $z^{[1] (i)}$ 和 $a^{[1] (i)}$ 也进行横向的叠加。那么在这些矩阵中，横向指标对应了不同的样本，而纵向指标则对应了不同的节点。 下面给出了向量化的计算公式，对于本例中的神经网络，$W^{[1]}$ 是 4x3 的矩阵。 $$\\largeZ^{[1]} = W^{[1]}X + b^{[1]} \\A^{[1]} = \\sigma(Z^{[1]}) \\Z^{[2]} = W^{[1]}X + b^{[2]} \\A^{[2]} = \\sigma(Z^{[2]})$$ 为什么这样的向量化是正确的呢？下图给出了解释，如果你了解线性代数，那么你可以看出这张图片中的解释是正确的，我们用矩阵 $W^{[1]}$ 与各个样本向量相乘，就得到了矩阵 $Z^{[1]}$，为了方便起见，这里省略了 $b^{[1]}$ 这一项。这里只解释了 $Z^{[1]} = W^{[1]}X + b^{[1]}$ 为什么成立，参考这一解释，你可以推导出其他几个式子也是正确的。 激活函数除了常见的 sigmoid 函数以外，激活函数还有其它的几种选择。 上图中第一个就是我们熟悉的 sigmoid 函数，除非在二分类的输出层，不然绝对不要用它作为激活函数。这是因为，tanh 函数，上图右上角所示，几乎在所有场合都更优越。最常用的默认激活函数是 ReLU（修正线性单元）。当你不确定时，最好选择 ReLU。图中最后一个函数我们称为 “带泄露的ReLU”|名称|公式|特点||:-:|:-:|:-:||sigmoid|$\\large g(z) = \\frac{1}{1+e^{-z}}$|除了二分类的输出层，几乎不用||tanh|$\\large g(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}$|几乎在所有场合都优于 sigmoid||ReLU|$\\large g(z) = max(0,z)$|当 z 很大时导数不会趋于0而导致速度过慢||带泄露的 ReLU|$\\large g(z) = max(0.01z,z)$|当 z 小于 0 时，导数不是0| 为什么一定要用非线性的激活函数呢？如果不使用非线性的激活函数，那么神经网络的运算就只有线性运算。神经网络最后的输出结果只是输入特征的线性组合。这和没有任何隐藏层的标准逻辑回归是一样的，这样就无法学习到更复杂的函数。 激活函数的导数 名称 公式 导数 sigmoid $\\large g(z) = \\frac{1}{1+e^{-z}}$ $\\large g’(z)=\\frac{1}{1+e^{-z}}(1-\\frac{1}{1+e^{-z}})=g(z)(1-g(z))$ tanh $\\large g(z) = \\frac{e^z-e^{-z}}{e^z+e^{-z}}$ $\\large g’(z)=1-(g(z))^2$ ReLU $\\large g(z) = max(0,z)$ $\\large if\\quad z &gt; 0 \\quad g’(z)=1 \\\\ if\\quad z&lt;0 \\quad g’(z)=0$ 带泄露的 ReLU $\\large g(z) = max(0.01z,z)$ $\\large if\\quad z &gt; 0 \\quad g’(z)=1 \\\\ if\\quad z&lt;0 \\quad g’(z)=0.01$ 神经网络的梯度下经法","link":"/post/deeplearning-ai-week-3/"},{"title":"机器学习笔记（1）单变量线性回归","text":"机器学习中一种经典的算法 场景描述我们有关于房屋面积和房屋价格的数据集，现在想拟合一条直线通过房屋的面积来预测房屋价格。这条直线应该尽可能的符合已有的数据。 概念介绍假设函数这里我们简单的假设该直线的方程为 $$h(x) = \\Theta x$$ 其中x表示房屋的面积，h(x) 表示预测出的房价。有了这个假设函数我们就可以预测房价了。那么参数$\\Theta$应该怎么确定呢？这里我们需要用到代价函数。 代价函数这里先给出代价函数的表达式$$J(\\Theta)=\\frac{1}{2m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$ 其中 ${x}^{(i)}$表示第i个数据样本中房屋的面积 ${h_\\Theta}({x}^{(i)})$表示使用假设函数预测房屋面积${x}^{(i)}$的得到的房屋价格 ${y}^{(i)}$表示真实的房屋价格 这里我们选择使用均方误差作为衡量预测结果与真实值的偏差。最前面的 $\\frac{1}{2}$ 只是为了计算方便无需在意。 我们所要做的就是改变$\\Theta$的值，使得代价函数J$(\\Theta)$的值最小,当找到一个$\\Theta$使得代价函数的值最小时，我们就确定了参数$\\Theta$。即我们的优化目标：$$minimizeJ(\\Theta)$$ 为什么说我们要找的$\\Theta$会使代价函数取得最小值呢？接下来举例说明。 代价函数详解代价函数与参数$\\Theta$的关系假设我们的数据集中有三个样本点 (1,1) , (2,2) , (3,3)我们可以使用无数条直线来拟合这些样本，但很显然只有当 $\\Theta = 1$时，即 $y=x$ 这条直线有最好预测效果。然后我们将不同的$\\Theta$值带入代价函数，计算其结果： 从图像上可知，当代价函数的图像在最低点时，对应$\\Theta$的值，就是最佳的结果。 通过这个例子不难发现，只要我们求出代价函数的最小值，就可找到我们想要的参数$\\Theta$的值。 那么代价函数的最小值应该怎么求呢？在数学上有许多方法可以解决这个问题，这里我们使用梯度下降法来求代价函数的最小值。 梯度下降法下图是使用梯度下降法求解$\\Theta$的步骤，开始时我们随机赋给$\\Theta$一个初值，重复执行下面的步骤更新$\\Theta$的值。执行一定次数，当$\\Theta$的值基本不再变化时，我们就求出了$\\Theta$的最后结果。 $$\\Theta = \\Theta - \\alpha\\frac{\\partial{J(\\Theta)}}{\\partial\\Theta}$$ 其中关键的步骤是对代价函数求$\\Theta$的偏导，这可以理解为在求某一点的斜率。 当$\\Theta$的值大于最终结果时，$\\Theta$的取值在最终结果的右边，对应点的斜率大于0，即求出的偏导值大于0， $\\Theta$减去一个大于0的数变小。 当$\\Theta$的值小于最终结果时，$\\Theta$的取值在最终结果的左边，对应点的斜率小于0，即求出的偏导值小于0， $\\Theta$减去一个小于0的数后变大。 当$\\Theta$的值越接近最终结果时，导数越接近0，$\\Theta$变化的速度也越慢。 其中 $\\alpha$ 是学习率，它的大小会改变$\\Theta$的改变速度，但取值不能太大，否则会造成$\\Theta$无法收敛。","link":"/post/machine-learning-AndrewNg-univariate-linear-regression/"},{"title":"机器学习笔记（4）正则化","text":"正则化是解决过拟合问题的一种有效手段。 过拟合定义：如果我们有太多的特征，这时训练出的假设能很好地拟合训练集（代价函数的值约等于0），当不能很好地泛化到新的样本中。泛化是指一个假设模型应用到新样本的能力。 解决过拟合 减少特征的数量 人工选择需要保留的特征 模型选择算法 正则化 保留所有特征，减小参数$\\theta$的值 当我们有很多特征，且或多或少都对预测 y 有影响，正则化也可以工作的很好 正则化 我们给代价函数新增了两项，并给 $\\theta_3$ 和 $\\theta_4$加上很大的系数，这样为了让代价函数的值最小，$\\theta_3$ 和 $\\theta_4$的值就会趋近与 0。最后的效果就好像我们在假设函数中直接去掉了这两项一样。 $$\\Large Features:x_1,x_2,…,x_{100} $$$$\\Large Parameters:\\theta_0,\\theta_1,\\theta_2,…,\\theta_{100}$$事实上，我们的问题中可能会有很多特征，但事先我们不知道该选择哪一个来缩小它们的值，所以我们需要缩小所有的值。如此，代价函数需要作出这样的修改：$$\\Large J(\\Theta)=\\frac{1}{2m}\\Huge[\\Large\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}+\\lambda\\sum_{i=2}^m\\theta_j^2\\Huge]$$其中 $\\lambda\\sum_{i=2}^m\\theta_j^2$ 是正则项，$\\lambda$ 是正则化参数。 当我们的正则化参数 $\\lambda$ 设置的过大时，可能会造成欠拟合的情况。因为此时的参数 $\\theta_j$ 都已经趋近于 0。 线性回归的正则化梯度下降 $$ \\Large repeat\\left\\{ \\begin{aligned} \\Theta_0 = \\Theta_0-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_0^{(i)} \\qquad \\qquad\\\\ \\Theta_j = \\Theta_j-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_j^{(i)} +\\frac{\\lambda}{m}\\theta_j , j\\not ={0} \\end{aligned} \\right\\} $$ 这里我们的 $\\theta_0$ 并不需要正则化。 正规方程 $$\\large X = \\underbrace{\\begin{bmatrix} (x^{(1)})^T\\\\ (x^{(2)})^T\\\\ (x^{(3)})^T\\\\ ....\\\\ (x^{(m)})^T\\\\ \\end{bmatrix}}_{m * (n+1)} \\qquad y = \\begin{bmatrix} y^{(0)} \\\\ y^{(1)} \\\\ y^{(2)} \\\\ ... \\\\ y^{(3)} \\end{bmatrix} \\qquad $$ 这时原来的方程$$\\large\\Theta = (X^TX)^{-1}X^Ty$$我们为其添加新的一项$$\\large \\Theta = (X^TX \\qquad\\underbrace{\\lambda\\begin{bmatrix}0 &amp; … &amp; 0 \\… &amp; 1 &amp; … \\0 &amp; … &amp; 1 \\\\end{bmatrix}}_{(n+1)*(n+1)})^{-1}X^Ty$$这样就实现了正规方程的正则化。By the way，当 $\\lambda$ 大于0时，括号内的矩阵肯定是可逆的。 逻辑回归的正则化代价函数在逻辑回归中代价函数也做了相应的变化 $$ \\large J(\\theta) = \\Huge[ \\large -\\frac{1}{m}\\sum_{i=1}^m y^{(i)}log(h_\\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\\theta(x^{(i)})) \\Huge]\\large + \\frac{\\lambda}{2m}\\sum_{j=1}^n\\theta_j^2 $$ 梯度下降 $$ \\Large repeat\\left\\{ \\begin{aligned} \\Theta_0 = \\Theta_0-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_0^{(i)} \\qquad \\qquad\\\\ \\Theta_j = \\Theta_j-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_j^{(i)} +\\frac{\\lambda}{m}\\theta_j , j\\not ={0} \\end{aligned} \\right\\} $$","link":"/post/machine-learning-AndrewNg-regularization/"},{"title":"机器学习笔记（2）多变量线性回归","text":"本篇介绍了有关在多特征的情况下如何使用线性回归，以及一些相关的技巧。 场景描述在多数时候我们的特征并不会只有一个。在预测房价的例子中，除了房屋的面积之外，房屋的房间数，楼层，房屋的年龄等也可以用于房价的预测。 面积($x_1$) 房间数($x_2$) 楼层($x_3$) 房屋年龄($x_4$) 价格(y) 2101 3 2 20 460 1236 3 1 40 232 1514 2 2 50 315 符号注释 :n : 特征的数量$x^{(i)}$ : 第i个训练样本的特征向量$x^{(i)}_j$ : 第i个训练样本的第j个特征值 例 : $$x^{(2)} = \\begin{bmatrix} 1236 \\\\ 3 \\\\ 1 \\\\ 40 \\end{bmatrix} \\qquad x_3^{(2)} =1$$ 假设函数因为特征的数量增加，假设函数也做出了相应的变化$$h_\\Theta(x) = \\Theta_0 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3 + … + \\Theta_nx_n $$为了书写的方便，我们定义一个$\\quad x_0=1 \\quad$ 即 $(x_0^{(i)}=1)$于是我们有 ：$$h_\\Theta(x) = \\Theta_0x_1 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3 + … + \\Theta_nx_n $$ 为进一步简化这个表达式，我们使用向量的方式来表示 ： $$X=\\begin{bmatrix} x_0\\\\x_1\\\\x_2\\\\x_3\\\\...\\\\x_n \\end{bmatrix} \\qquad \\Theta=\\begin{bmatrix} \\Theta_0\\\\\\Theta_1\\\\\\Theta_2\\\\\\Theta_3\\\\...\\\\\\Theta_n \\end{bmatrix}$$ $$h_\\Theta(x) = \\underbrace{ \\Theta_0x_0 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3 + … + \\Theta_nx_n}_{\\Theta^TX} $$ $$\\Huge\\Downarrow $$ $$h_\\Theta(x) = \\Theta^TX$$ 代价函数$$J(\\Theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\Theta(x^{(i)}) - y^{(i)})$$ 梯度下降 $$Repeat\\left\\{ \\Theta_j = \\Theta_j - \\alpha\\frac{\\partial}{\\partial\\Theta_j}J(\\Theta_0,...,\\Theta_n) \\right\\} $$ 需要注意的是，这里的$\\Theta_j$需要同步更新 同步更新 异步更新 temp0 = $\\alpha\\frac{\\partial}{\\partial\\Theta_0}J(\\Theta_0,…,\\Theta_n)$ temp1 = $\\alpha\\frac{\\partial}{\\partial\\Theta_1}J(\\Theta_0,…,\\Theta_n)$ $\\Theta_0$ = temp0$\\Theta_1$ = temp1 temp0 = $\\alpha\\frac{\\partial}{\\partial\\Theta_0}J(\\Theta_0,…,\\Theta_n)$ $\\Theta_0$ = temp0 temp1 = $\\alpha\\frac{\\partial}{\\partial\\Theta_1}J(\\Theta_0,…,\\Theta_n)$$\\Theta_1$ = temp1 特征缩放(Feature Scaling)确保特征的数值大小在相似的规模下，这样梯度下降法可以更快的收敛。在做特征缩放时并不需要太精确，只是为了使梯度下降法能更快的收敛。 缩放前 缩放后 $x_1 = size(0-2000 feet^2)$ $x_1 = \\frac{size(feet^{2})}{2000} \\,(0\\leq x_1 \\leq 1)$ $x_2=number \\, of \\, bedrooms(1-5)$ $x_1 = \\frac{num \\, of \\, bedrooms}{5} \\,(0\\leq x_2 \\leq 1)$ 均值归一化(Mean normalization)特征缩放的一种方法$$x_1 \\Rightarrow \\frac{x_1 - \\mu_1}{S_1}$$$\\mu_1$ 表示训练集中特征$x_1$的平均值$S_1$ 表示该特征值的范围（max - min） 多项式回归多项式回归就是用线性回归的方式去拟合更复杂的函数，甚至是非线性的函数。 特征选择如图所示，我们有两个特征，房子的临街宽度和垂直深度。但我们通常使用面积来表示房屋的大小。所以我们可以使用房屋的面积（临街宽度 x 垂直深度）作为一个特征。 拟合多项式对于下图中的数据集，我们继续使用一次函数来拟合的话，效果并不太好。如果使用二次函数来拟合的话，效果可能也不是特别好，因为我们知道，二次函数的图像（图中蓝色的线）在后面是一个下降的趋势，然而现实中房价并不会随着房屋面积的增加而减少。所以这里我们可以使用三次函数（图中绿色的线）来拟合。我们只要做一些简单的修改就可以将线性回归应用到多项式上。$$h_\\Theta(x)=\\Theta_0 + \\Theta_1x_1 + \\Theta_2x_2 + \\Theta_3x_3$$$$\\huge\\Downarrow$$$$h_\\Theta(x)=\\Theta_0 + \\Theta_1size + \\Theta_2(size)^2 + \\Theta_3(size)^3\\$$我们令$$x_1=(size)\\ x_2=(size)^2\\ x_3=(size)^3$$即可。需要强调的是，在这种情况下特征缩放就显得尤为重要。 检验方法我们如何判断梯度下降法是否正常工作呢？通常可以观察代价函数的值与迭代次数的关系来判断。当梯度下降法正常运行时，如下图所示，随着迭代次数的增加，代价函数的值越来越小，当梯度下降算法迭代60次左右时，代价函数的值几乎不再变化，说明此时算法已经收敛。当出现以下两种情况时，代价函数的值上下震荡，或是逐渐变大，这都说明梯度下降法并没有正常工作。通常出现这两种情况的原因都是学习率 $\\alpha$ 过大。 学习率选择总的来说学习率过小的话，会导致收敛过慢而学习率过大的话，可能导致无法收敛，代价函数 $J(\\Theta)$ 并不会在每次迭代之后都下降。我们可以通过多次试验的方式找出合适的学习率值的大小。另：按照吴恩达老师的推荐，我们可以如下依次选择学习率的大小。… 0.001，0.03，0.1，0.3 … 正规方程正规方程可以让我们再某些情况下，更快的求解出参数 $\\Theta$。假设我们有m个样本，$(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(n)},y^{(n)})$ ,n 个特征。我们将单个样本的特征写成向量形式，再将所有的向量转置后，写成矩阵形式。 $$ x_{(i)} = \\begin{bmatrix} x_0^{(i)} \\\\ x_1^{(i)} \\\\ x_3^{(i)} \\\\ ... \\\\ x_n^{(i)} \\end{bmatrix} \\qquad X = \\underbrace{\\begin{bmatrix} ---(x^{(1)})^T---\\\\ ---(x^{(2)})^T---\\\\ ---(x^{(3)})^T---\\\\ ---------\\\\ ---(x^{(m)})^T---\\\\ \\end{bmatrix}}_{m * (n+1)} $$ 接着，只要求解如下这个矩阵表达式，就可得到参数$\\Theta$的值$$\\Theta = (X^TX)^{-1}X^Ty$$在上式中需要对矩阵求逆，那么如果矩阵不可逆呢？一般来说，大部分矩阵都是可逆的，出现了以下两种情况时，会导致矩阵不可逆: 多余特征如下所示，显然$x_1$和$x_2$两个特征是线性相关的，那么这时就会导致矩阵不可逆$$x_1 = size \\ in \\ feet^2 \\ x_2 = size \\ in \\ m^2$$ 太多特征如果我们的特征数量较多，而样本数量较少，造成特征数量大于样本数量，这种情况下也会导致矩阵不可逆。例如，生物信息学的基因芯片数据中常有成千上万个属性，但往往只有几十，上百个样例。 正规方程与梯度下降法比较 梯度下降 正规方程 缺点 需要多次迭代 需要选择学习率 优点 不需要多次迭代 不需要选择学习率 优点 当特征数量n很大时，也能运行的很好 缺点 当特征数量n较大时，速度很慢 吴恩达老师推荐，当n大于10000时选择梯度下降法，小于10000时选择正规方程法。","link":"/post/machine-learning-AndrewNg-multivariate-linear-regression.md/"},{"title":"机器学习（吴恩达）作业（1）","text":"单变量线性回归在这部分的练习中，你将使用单变量的线性回归来预测食品卡车的利润。假设你是a公司的CEO并正在考虑在不同的城市开设一家连锁餐厅。该连锁店已经在多个城市拥有卡车，并且你拥有有关城市的人口和利润的数据。你可以使用这些数据来帮助你选择接下来在那个城市发展。文件ex1data1.txt包含了线性回归问题的数据集，其中第一列是城市人口，第二列是食品卡车在该城市的利润。 绘制数据图像再开始任务之前，我们通过数据可视化来更好的理解数据。因为这个数据集只有两个属性，所以我们可以使用散点图来进行可视化。（我们在现实生活中遇到的很多问题往往是多维的，不能进行二维的绘制） 首先要载入数据,载入数据后我们将其打印在屏幕上1234567print(\"loading data ex1data1.txt...\")ex1data = loadtData('ex1data1.txt')X = ex1data[0]y = ex1data[1]print(X)print(y)print() loadData 函数实现1234567891011121314# 载入数据，返回一个二维的numpy数组，# 第一维是 x轴数据，第二维是 y轴数据def loadtData(file_path): X = np.array([]) Y = np.array([]) for i in open(file_path): # 根据逗号的位置取出数据 x = i[0:i.index(',')-1] y = i[i.index(',')+1:len(i)-1] # 读出的数据是字符串类型，需要转换为浮点类型 X = np.append(X,float(x)) Y = np.append(Y,float(y)) return np.array([X,Y]) 绘制图像接下来我们调用plotData 函数来绘制散点图，顺便设置一下横纵坐标的标题1234x_label = \"Population of City in 10,000s\"#设置横纵坐标的标题y_label = \"Profit in $10,000s\"plotData(X,y,x_label,y_label) plotData函数实现 123456# 将数据可视化,使用散点图def plotData(X,y,x_label,y_label): plt.scatter(X,y) plt.xlabel(x_label) plt.ylabel(y_label) plt.show() 绘制出来的结果应该与下图类似 梯度下降在这一部分，你将使用梯度下降法来拟合单变量线性回归中的参数$\\theta$,使其与我们的数据集相符 更新方程线性回归的目标是使代价函数达到最小值$$J(\\Theta)=\\frac{1}{2m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$假设函数使用下面的线性模型$$h_\\theta(x) = \\theta^Tx = \\theta_0 +\\theta_1x_1$$重新计算模型中参数$\\theta$的值，通过调整参数的值使代价函数的值最小化。我们使用批次梯度下降法来达到目的。在梯度下降法中，每一次迭代都会完成一次更新$$\\theta_j = \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$需要注意的是，所有的$\\theta_j$需要同时更新。梯度下降的每一次更新都会使参数$\\theta_j$更接近最优的值，同时这也会使代价函数的值达到最小。 实现在上面的步骤中，我们已经准备好了线性回归所需的数据。接着，我们给数据增加一个维度，方便我们对参数$\\theta_0$进行优化。我们将参数$\\theta$都初始化为0，并设置学习率为0.01。 123456m = len(y)#样本数量X = np.c_[np.ones(m),X]#为X增加一行 值为1theta = np.zeros((2,1),float)#初始化参数theta#一些梯度下降的设置iterations = 1500 #迭代次数alpha = 0.01 #学习率 计算代价函数当我们使用梯度下降法来最小化代价函数的值时，我们可以通过计算代价函数的值来判断是否收敛。我们接下来的任务就是实现computeCost()函数，该函数的功能就是计算代价函数的值。当我们在实现该函数的时候，需要注意变量X，y是矩阵类型的变量，而不是标量。矩阵的行代表了训练集中的样本。一旦你实现了这个函数，我们就使用初始化为0的参数$\\theta$来运行一次该函数。该函数的运行结果应该是32.07 12345678910111213# 计算并显示初始的代价值J = computeCost(X,y,theta)print('With theta = [0 ; 0] ');print(\"Cost computed = %f \\n\" % J)print('Expected cost value (approx) 32.07\\n');# 继续测试代价函数theta[0] = -1theta[1] = 2J = computeCost(X, y, theta);print('\\nWith theta = [-1 ; 2]\\nCost computed = %f\\n'% J);print('Expected cost value (approx) 54.24\\n'); computeCost函数实现 123456789# 计算代价函数def computeCost(X,y,theta): m = len(y) result = np.dot(X , theta) result = result - y.reshape(97,1) result = np.square(result) result = np.sum( result,axis=0) result = result/(2.0*float(m)) return result 梯度下降接下来你要完成梯度下降的编码。在你的程序中，你要清楚的理解优化目标是什么，什么是需要更新的。你要记住，代价函数的参数是向量$\\theta$,而不是X，y。也就是说，我们需要更新向量$\\theta$的值来是代价函数最小化，而不是改变 X 或 y。如果你不确定的话，参考上面给出的方程，或是视频的课程。我们可以通过观察代价函数的值在每一次更新中是否持续下降，以此来判断梯度下降法是否正常工作。梯度下降在每一次迭代中都会调用computeCost函数，如果你正确实现了computeCost函数和梯度下降，那么你的代价函数的值绝不会增加，并且将会在算法的最后达到一个稳定的值。 123456789print('\\nRunning Gradient Descent ...\\n')# 运行梯度下降theta = gradientDescent(X, y, theta, alpha, iterations);# 将theta的值打印到屏幕上print('Theta found by gradient descent:\\n');print('theta_0 : %f \\ntheta_1 : %f'%(theta[0],theta[1])) ;print('Expected theta values (approx)\\n');print(' -3.6303\\n 1.1664\\n\\n'); gradientDescent 函数实现 123456789101112131415161718# 梯度下降def gradientDescent(X, y, theta, alpha, iterations): m = len(y) for i in range(0,iterations): theta_0 = theta[0] - alpha * computePartialDerivative(X,y,theta,0) theta_1 = theta[1] - alpha * computePartialDerivative(X,y,theta,1) theta[0] = theta_0 theta[1] = theta_1 print( \"iterations : \",i, \" cost : \",computeCost(X,y,theta)) return theta# 计算偏导数def computePartialDerivative(X , y, theta , num): m = len(y) result = 0 for i in range(0,m): result += (theta[0]*X[i][0] + theta[1]*X[i][1] - y[i])*X[i][num] result /= m return result 当你完成了以上任务时，使用最后得到的参数$\\theta$的值来绘制假设函数的图像，你会看到与下面类似的图 1234# 绘制线性拟合的图plt.plot(X[:,1],np.dot(X,theta))plt.scatter(X[:,1],y,c='r')plt.show() 可视化 J($\\theta$)为了更好的理解代价函数 J($\\theta$) , 我们可以将$\\theta_0$和$\\theta_1$的值绘制在二维的网格上。绘图代码 12345678910111213141516171819# 绘制三维的图像fig = plt.figure()axes3d = Axes3D(fig)# 指定参数的区间theta0_vals = np.linspace(-10, 10, 100)theta1_vals = np.linspace(-1, 4, 100)# 存储代价函数值的变量初始化J_vals = np.zeros((len(theta0_vals), len(theta1_vals)))# 为代价函数的变量赋值for i in range(0,len(theta0_vals)): for j in range(0,len(theta1_vals)): t = np.zeros((2,1)) t[0] = theta0_vals[i] t[1] = theta1_vals[j] J_vals[i,j] = computeCost(X, y, t)# 下面这句代码不可少，matplotlib还不熟悉，后面填坑theta0_vals, theta1_vals = np.meshgrid(theta0_vals, theta1_vals) #必须加上这段代码axes3d.plot_surface(theta0_vals,theta1_vals,J_vals, rstride=1, cstride=1, cmap='rainbow')plt.show() 完整代码最后附上完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124import numpy as npimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3D# 载入数据，返回一个二维的numpy数组，# 第一维是 x轴数据，第二维是 y轴数据def loadtData(file_path): X = np.array([]) Y = np.array([]) for i in open(file_path): # 根据逗号的位置取出数据 x = i[0:i.index(',')-1] y = i[i.index(',')+1:len(i)-1] # 读出的数据是字符串类型，需要转换为浮点类型 X = np.append(X,float(x)) Y = np.append(Y,float(y)) return np.array([X,Y])# 将数据可视化,使用散点图def plotData(X,y,x_label,y_label): plt.scatter(X,y) plt.xlabel(x_label) plt.ylabel(y_label) plt.show()# 计算代价函数def computeCost(X,y,theta): m = len(y) result = np.dot(X , theta) result = result - y.reshape(97,1) result = np.square(result) result = np.sum( result,axis=0) result = result/(2.0*float(m)) return result# 梯度下降def gradientDescent(X, y, theta, alpha, iterations): m = len(y) for i in range(0,iterations): theta_0 = theta[0] - alpha * computePartialDerivative(X,y,theta,0) theta_1 = theta[1] - alpha * computePartialDerivative(X,y,theta,1) theta[0] = theta_0 theta[1] = theta_1 print( \"iterations : \",i, \" cost : \",computeCost(X,y,theta)) return theta# 计算偏导数def computePartialDerivative(X , y, theta , num): m = len(y) result = 0 for i in range(0,m): result += (theta[0]*X[i][0] + theta[1]*X[i][1] - y[i])*X[i][num] result /= m return result#======================== 绘图 ====================================print(\"loading data ex1data1.txt...\")ex1data = loadtData('ex1data1.txt')X = ex1data[0]y = ex1data[1]print(X)print(y)print()x_label = \"Population of City in 10,000s\"#设置横纵坐标的标题y_label = \"Profit in $10,000s\"#绘图plotData(X,y,x_label,y_label)#======================= 代价函数 和 梯度下降 ======================m = len(y)#样本数量X = np.c_[np.ones(m),X]#为X增加一行 值为1theta = np.zeros((2,1),float)#初始化参数theta#一些梯度下降的设置iterations = 1500 #迭代次数alpha = 0.01 #学习率print(\"Testing the coust function ...\\n\")# 计算并显示初始的代价值J = computeCost(X,y,theta)print('With theta = [0 ; 0] ');print(\"Cost computed = %f \\n\" % J)print('Expected cost value (approx) 32.07\\n');# 继续测试代价函数theta[0] = -1theta[1] = 2J = computeCost(X, y, theta);print('\\nWith theta = [-1 ; 2]\\nCost computed = %f\\n'% J);print('Expected cost value (approx) 54.24\\n');print('\\nRunning Gradient Descent ...\\n')# 运行梯度下降theta = gradientDescent(X, y, theta, alpha, iterations);# 将theta的值打印到屏幕上print('Theta found by gradient descent:\\n');print('theta_0 : %f \\ntheta_1 : %f'%(theta[0],theta[1])) ;print('Expected theta values (approx)\\n');print(' -3.6303\\n 1.1664\\n\\n');# 绘制线性拟合的图plt.plot(X[:,1],np.dot(X,theta))plt.scatter(X[:,1],y,c='r')plt.show()# 绘制三维的图像fig = plt.figure()axes3d = Axes3D(fig)# 指定参数的区间theta0_vals = np.linspace(-10, 10, 100)theta1_vals = np.linspace(-1, 4, 100)# 存储代价函数值的变量初始化J_vals = np.zeros((len(theta0_vals), len(theta1_vals)))# 为代价函数的变量赋值for i in range(0,len(theta0_vals)): for j in range(0,len(theta1_vals)): t = np.zeros((2,1)) t[0] = theta0_vals[i] t[1] = theta1_vals[j] J_vals[i,j] = computeCost(X, y, t)# 下面这句代码不可少，matplotlib还不熟悉，后面填坑theta0_vals, theta1_vals = np.meshgrid(theta0_vals, theta1_vals) #必须加上这段代码axes3d.plot_surface(theta0_vals,theta1_vals,J_vals, rstride=1, cstride=1, cmap='rainbow')plt.show()","link":"/post/machine-learning-AndrewNg-ex1/"},{"title":"机器学习笔记（3）逻辑回归","text":"在线性回归中我们需要预测的是连续的值，而在逻辑回归中我们需要预测的是离散值。虽然该算法中有“回归”二字，但是做的是分类的问题。 场景描述线性回归有以下的应用场景，例如邮件的过滤，需要判断一封邮件是否是垃圾邮件。又或是肿瘤的诊断，需要判断肿瘤是良性或是恶性等等。 基本概念应该如何构建一个分类算法呢？先来看看将我们前面所学的线性回归直接应用到分类问题中会怎么样。在肿瘤的例子中，我们选择肿瘤的大小这一特征来预测肿瘤是良性还是恶性。 我们这里定义 $y\\in \\left\\{ 0,1 \\right\\}$ , 0 代表良性肿瘤，1 代表恶性肿瘤。下图中我们有几个正例和反例，且我们已经根据样本拟合出了一条假设函数的直线。我们将输出的阈值设为0.5，当假设函数的输出值大于等于0.5时，我们预测 y = 1 ，当输出值小于0.5时我们预测 y = 0。根据这条直线我们可预测当肿瘤的size大于这一点（y=0.5时，直线上的点）时我们预测 y = 1，小于这一点时我们则预测 y = 0。这样看来这个假设函数可以很好的将正负样本区分开来，线性回归在分类的表现上似乎很不错，但是且慢，让我们看下面的例子：这里我们新增加了一个样本点，并且根据这个新的训练集拟合出了一个新的假设函数，该假设函数的图像如上方蓝色直线所示。从这条直线看来，分类的效果并不好，蓝色点左边的预测 y = 0，右边的预测为 y = 1 则它对相当一部分的样本点做出了错误的预测。由此可见线性回归并不适合直接应用到分类的任务中。 逻辑回归模型其实我们稍作修改就可以将线性回归应用到分类问题中。我们需要给定一个新的假设函数，这个新的假设函数输出的值应该在0到1之间（$0\\leq h_\\theta\\leq1$）。下面我们给出新的假设函数的定义：$$\\Large h_\\theta(x)=g(\\Theta^Tx)$$$$\\huge\\qquad\\Downarrow \\normalsize Z=\\Theta X$$$$\\Large h_\\theta(x)=g(Z)=\\frac{1}{1+e^{-Z}}=\\frac{1}{1+e^{-\\Theta X}}$$其中$g(Z) = \\frac{1}{1+e^{-Z}}$是对数几率函数，它单调可微，是一种“Sigmoid 函数”它将Z值转化为一个接近 0 或 1 的 y 值，并且其输出值在 Z = 0 附近变化很陡。注：Sigmoid 函数即形似 S 的函数，对率函数是 Sigmoid 函数最重要的代表 假设函数的解释$h_\\theta(x)=$输入一个 x，给出 y = 1 的概率估计。例：当 $x = \\begin{bmatrix}x_0\\\\ x_1\\end{bmatrix} = \\begin{bmatrix}1\\\\ tumor\\,size\\end{bmatrix}$时，$h_\\theta(x) =0.7$我们可以说，有70%的概率肿瘤是恶性的。 决策边界 从上面 Sigmoid 函数的图像可以看出，当我们将假设函数的阈值设为 0.5 时，Z的值在 0 处便成为了一个分界点。当$h_\\theta \\geq0.5$ , 我们预测 y = 1当$h_\\theta &lt;0.5$ , 我们预测 y = 0即当$Z \\geq 0$ , 我们预测 y = 1当$Z &lt; 0$ , 我们预测 y = 0 假设我们有一个如下图所示的一个训练集 我们有了以下的假设函数，并已经拟合出了参数$\\Theta$$$\\Large h_\\theta(x)=g(\\theta_0+\\theta_1x_1+\\theta_2x_2)$$$$\\Huge\\Downarrow\\normalsize \\Theta=\\begin{bmatrix} -3 \\\\ 1 \\\\ 1 \\end{bmatrix}$$$$\\Large h_\\theta(x)=g(-3+x_1+x_2)$$那么，我们可以预测当 $-3+x_1+x_2\\geq0$时， y = 1当 $-3+x_1+x_2&lt;0 $时， y = 0这里可以看出$x_1+x_2=3$ 可以作为预测的分界线，接着我们在图中做出关于$x_1,x_2$的图像，即图中红色的线。我们将这个线称为“决策边界” 假设函数的不同，得到的决策边界也不尽相同。当假设函数变得复杂时，我们也可以得到非线性的决策边界。比如下面的例子 $$\\Large h_\\theta(x)=g(\\theta_0+\\theta_1x_1+\\theta_2x_2+\\theta_3x_1^2+\\theta_4x_2^2)$$$$\\huge\\Downarrow\\normalsize \\Theta =\\begin{bmatrix}-1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$$$$\\Large h_\\theta(x)=g(-1+x_1^2+x_2^2)$$我们可以得到决策边界 $x_1^2+x_2^2=1$ 当假设函数更复杂的话，我们可以得到更加有趣的决策边界： 需要注意的是，决策边界不是训练集的属性，而是假设函数本身及其参数的属性。只要给定了参数向量$\\Theta$，决策边界就决定了。我们不是用训练集来定义决策边界，而是用训练集来拟合参数$\\Theta$ 代价函数既然我们有了假设函数，那么我们就需要通过代价函数拟合出参数$\\Theta$的值。我们再来回顾一下线性回归的大家函数，并对其的表示方法做一些改进：$$\\Large J(\\Theta)=\\frac{1}{2m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$$$\\Huge\\Downarrow$$$$\\Large J(\\Theta)=\\frac{1}{m}\\sum_{i=1}^{m}\\underbrace{\\frac{1}{2}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}}$$$$\\qquad\\qquad\\qquad\\qquad\\Huge\\Downarrow$$$$\\Large cost(h_\\theta(x),y) = \\frac{1}{2}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}^{2}$$ 如果直接将假设函数带入到这个代价函数中的话，即令$\\Large h_\\theta(x)=\\frac{1}{1+e^{-\\Theta X}}$我们将会得到一个非凸优化问题。而这并不是我们想看到的。所以我们需要一个新的代价函数。 逻辑回归的代价函数 $$ \\Large cost(h_\\theta) =\\left\\{ \\begin{aligned} -log(h_\\theta(x)) \\qquad y=1 \\\\ -log(1-h_\\theta(x)) \\qquad y=0 \\end{aligned} \\right. $$ 为了更加直观的了解逻辑回归的代价函数我们将其的图像画出：当 y = 1 时,从下图中可看出，若$h_\\theta(x)=1$ , cost = 0若$h_\\theta(x)=0$ , cost -&gt; $\\infty$也就是说，当真值为 1 时，而我们很肯定的预测它为 0 ，那么我们就使用很大的代价来“惩罚”这个算法 当 y = 0 时,从下图中可看出，若$h_\\theta(x)=0$ , cost = 0若$h_\\theta(x)=1$ , cost -&gt; $\\infty$ 同样的，当真值为 0 时，而我们很肯定的预测它为 1 ，那么我们就使用很大的代价来“惩罚”这个算法 这样我们就了解了这个代价函数的作用，当这个表示方法并不方便，我们需要根据 y 的值来决定使用哪个表达式。其实我们将其写进一个表达式中：$$\\Large cost(h_\\theta(x),y)=-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x))$$可以验证，这个表达式和原来的表达式是等价的。 我们写出代价函数的完整表达式$$\\Large J(\\theta) = \\frac{1}{m}cost(h_\\theta(x),y)$$$$\\Huge \\Downarrow$$$$\\Large J(\\theta) = -\\frac{1}{m}y^{(i)}log(h_\\theta(x^{(i)}))-(1-y^{(i)})log(1-h_\\theta(x^{(i)}))$$ 梯度下降直接给出梯度下降的公式 $$\\Large repeat\\left\\{\\Theta_j = \\Theta_j-\\alpha\\sum_{i=1}^m(h_\\theta(x^{(i)}-y^{(i)}))x_j^{(i)} \\right\\}$$ 这里仍需要同时更新所有的$\\Theta_j$认真的读者可以发现，这个梯度下降的公式和线性回归的公式是一样的，但实际上它们并不相同，因为此处的假设函数的定义已经改变了。 优化算法除了梯度下降法之外还需许多别的算法可以用来拟合参数，比如说 Conjugate gradient BFGS L-BFGS 这些算法相比于梯度下降法有如下优点： 无需选择血虚率 比梯度下降法更快 不可避免的也有缺点： 更加复杂难懂 这些算法内有一个智能内循环，称之为线搜索算法，它可以自动尝试不同的学习率，并自动选择一个好的学习率，甚至可以为每次迭代选择不同的学习率。 因为这些算法较复杂，在不了解其细节的情况下使用，可能会使模型的调试更加不透明一些，但在处理大规模的机器学习问题时，仍倾向于使用这些算法，而不是梯度下降算法。 多分类问题上面我们讲的都是二元分类问题，有时我们还会遇到多分元类的问题。如： 邮件分类问题，学习，工作，家庭，朋友等等 病情诊断，健康 感冒 发烧等 天气预测晴天，多云，下雨，下雪等 如图所示，我们的训练集中有三种类别的样本。我们可以为每一种类别构建一个分类器来实现多元分类。 首先我们创建一个新的训练集，将三角形设为正类，其它两类设为负类，根据这个训练集构建一个分类器。其余两类如此构建各自的分类器。 这样我们对每一种类别都有了各自的分类器，当输入新的 X 时，我们用所有的分类器对其进行预测，输出概率最高的一个（$max\\, h(\\theta^i(x)$)），便是最终的结果。 绘图代码最后放上一点绘图的代码 绘制 Sigmoid 函数 123456789101112131415161718192021222324252627282930313233#创建画布fig = plt.figure(figsize=(5, 5))#使用axisartist.Subplot方法创建一个绘图区对象axax = axisartist.Subplot(fig, 111) #将绘图区对象添加到画布中fig.add_axes(ax)# 通过set_visible方法设置绘图区所有坐标轴隐藏ax.axis[:].set_visible(False)# ax.new_floating_axis代表添加新的坐标轴ax.axis[\"x\"] = ax.new_floating_axis(0,0)# 给x坐标轴加上箭头ax.axis[\"x\"].set_axisline_style(\"-&gt;\", size = 1.0)# 添加y坐标轴，且加上箭头ax.axis[\"y\"] = ax.new_floating_axis(1,0)ax.axis[\"y\"].set_axisline_style(\"-|&gt;\", size = 1.0)# 设置x、y轴上刻度显示方向ax.axis[\"x\"].set_axis_direction(\"top\")ax.axis[\"y\"].set_axis_direction(\"right\")# 设置x、y轴标签ax.axis[\"x\"].label.set_text(\"Z\")ax.axis[\"y\"].label.set_text(\"g ( Z )\")# 设置坐标轴范围和标签plt.xlim(-10,10)plt.ylim(0,1)plt.ylabel(\"Z\")# plt.ylabel(\"g(Z)\")z = np.linspace(-10,10,1000)g = 1.0/(1+pow(math.e,-z))plt.plot(z,g) 代价函数的代码 1234567891011121314151617181920212223# cost() = -log(h(x))fig = plt.figure()x = np.linspace(0.0001,1,100)y = -(np.log(x))plt.xlabel(\"h(x)\")plt.xlim(0,1)plt.ylim(0,10)plt.plot(x,y)plt.show()# cost() = -log(1- h(x))fig = plt.figure()x = np.linspace(0,1,1000)y = -(np.log(1-x))plt.xlabel(\"h(x)\")plt.xlim(0,1)plt.ylim(0,10)plt.plot(x,y)plt.show()","link":"/post/machine-learning-AndrewNg-logistic-regression/"},{"title":"机器学习（吴恩达）作业（2）","text":"在这个练习中，我们将实现逻辑回归算法，并将它应用到两个不同的数据集中。 逻辑回归在这部分的练习中，你将创建一个逻辑回归的模型去预测某个学生能否进入大学。假定你是大学招生办的主任，你想要通过两次测验的结果来决定申请人是否能获得入学资格。 你已经有了前面的申请人的历史数据，你可以将它作为逻辑回归的训练集数据。每一个训练样本中包括申请人两次测验的分数和是否获得了入学资格。 你的任务是建立一个分类模型使用申请人在两次测验的分数给出其能否入学的可能性。 可视化数据如果可以的话，在实现任何学习算法之前先对数据进行可视化。我们需要实现 plotData 函数来载入数据并将其可视化。最后的结果应该如下图所示，两个坐标轴是两次测验的分数，并且正例和反例应该用不同的标记符号。 实现代码 123456789101112131415161718192021222324252627282930313233def loadData(file_path): count = len(open(file_path,'rU').readlines()) data = np.zeros(shape=(count,3),dtype=float) index = 0 for row in open(file_path): # 根据逗号的位置取出数据 # 读出的数据为字符串格式，需要转换为float格式 s1 = float(row[0:row.index(',')-1]) s2 = float(row[row.index(',')+1:len(row)-3]) label = int( row[len(row)-2]) data[index][0] = s1 data[index][1] = s2 data[index][2] = label index+=1 return datadef plotData(data,x_label,y_label): # 根据第三列的数据分为两部分显示 data_0 = data[data[:,2]==0] data_1 = data[data[:,2]==1] X_0 = data_0[:,0] y_0 = data_0[:,1] X_1 = data_1[:,0] y_1 = data_1[:,1] fig = plt.figure() plt.scatter(X_0,y_0,marker='o') plt.scatter(X_1,y_1,marker='v') plt.xlabel(x_label) plt.ylabel(y_label) plt.show() 实现sigmoid函数当你在开始实现代价函数之前，回忆一下逻辑回归的假设函数： $$\\large h_\\theta(x)=g(\\theta^TX)$$其中 g 函数 就是 sigmoid 函数，sigmoid 函数的定义：$$\\large g(z) = \\frac{1}{1+e^{-z}}$$ 你的第一步是实现 sigmoid 函数，当你完成编码之后，最好测试一下你实现的 sigmoid 函数。当你使用很大的整数来测试时，返回的值应该趋向于 1 ，使用很大的负数时，返回的值应该趋向于 0 。使用 0 来测试时，得到的值应该是 0.5 。你实现的函数应该也可以适用于向量和矩阵。对于矩阵类型的参数，你的函数应该对矩阵中的每一个值进行计算。 1234# simgoid 函数def sigmoid(z): z=1/(1+np.exp(-z)) return z 代价函数和梯度现在你将实现代价函数和梯度的计算。逻辑回归中的代价函数： $$ \\large J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m[-y^{(i)}log(h_\\theta(x^{(i)}))-(1-y^{(i)})log(1-h_\\theta(x^{(i)}))] $$ 代价的梯度是一个与参数 $\\theta$ 有着同样长度的向量，第 j 个元素的定义如下： $$ \\large \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^{m}{({h_\\Theta}({x}^{(i)})-{y}^{(i)})}x_j^{(i)} $$ 需要注意的是，梯度的公式看起来与线性回归的公式是相同的，但因为假设函数的不同其实质是不同的。当你实现 costFunction 函数之后使用初值为0的参数$\\theta$计算初始的代价值,得到的结果应该是 0.693 12345678910111213# 代价函数def costFunction(theta, X, y): m=X.shape[0] J = (-np.dot(y.T, np.log(sigmoid(X.dot(theta)))) - \\ np.dot((1 - y).T, np.log(1 - sigmoid(X.dot(theta))))) / m return J# 梯度def gradient(theta,X,y): m,n=X.shape theta=theta.reshape((n,1)) grad=np.dot(X.T,sigmoid(X.dot(theta))-y)/m return grad.flatten() 学习参数原作业中使用 octave 的 fminunc 函数来优化参数 $\\theta$ , 这里我们使用 python scipy 库中的 optimize 函数来优化。 在这个函数中会调用你写好的 costFunction 函数来优化参数，optimize 函数给出的最后结果应该是：cost 约等于 0.203。最后得到的 $\\theta$ 值将会用来绘制决策边界，如下图所示： 12345import scipy.optimize as opresult = op.minimize(fun=costFunction, x0=initial_theta, args=(X, y), method='TNC', jac=gradient)cost = result.funtheta = result.x 评估逻辑回归在学习参数之后，你可以使用这个模型去预测一个学生能否获得入学资格。如果一个学生测试1的分数为45，而测试而的分数为85，那么他获得入学资格的可能性应该为 0.776。另一个评估我们得到的参数的方式是模型在训练集上预测的结果如何。这里我们需要实现 predict 函数。如果一切正常的话，我们得到的在训练集上的准确率是0.89。 1234567891011# 预测函数def predict(theta,X): p = sigmoid(X.dot(theta)) p = np.where(p &gt; 0.5,1,0) p = p.reshape(len(p),1) return p# Compute accuracy on our training setp = predict(theta, X) print('Train Accuracy: ', np.mean(p == y) * 100)print('Expected accuracy (approx): 89.0') 正则化逻辑回归在这部分的练习中，你将实现正则化的逻辑回归算法，并用它去预测制造工厂生产的芯片能否通过质量保证（QA）。在 QA 中，一块芯片需要通过多个测试以确保它能够正常工作。假设你是工厂的产品经理，并且你有了一些芯片在两种不同测试中的结果。你将根据测试的结果来判断是否应该接受这批产品。为了帮助你做出决定，你可以使用过去的芯片的测试结果来建立一个逻辑回归模型。 可视化数据与前面的练习相似，使用 plotdata 函数是数据可视化，如下图所示，坐标轴是两次测试的分数，正例（y = 1 ， 接受），反例（y = 0，拒绝）样本使用不同的符号显示。 从上图中我们可以知道，我们的数据集中的正例和反例不能使用直线来分割。直接将逻辑回归应用在这个数据集中效果可能并不好，因为常规的逻辑回归只能得到线性的决策边界。 特征映射通过每个数据点来创造更多的特征可以更好的适应数据。在函数 mapFeature 中，我们将 x1 和 x2 映射到所有的 6 次多项式。 $$mapFeature(x) = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_1^2 \\\\ x_1x_2 \\\\ x_2^2 \\\\ x_1^3 \\\\ …\\\\ x_1x_2^5 \\\\ x_2^6\\end{bmatrix}$$ 我们将两个特征（在两个 QA 测试中的分数）转换成了 28 维的向量。一个逻辑回归的分类器在这样的高维向量上训练会得到更复杂的决策边界，当在 2 维的图像上绘制时，会呈现出非线性。尽管特征映射可以使我们构建出更有表现力的分类器，但同时它也更容易过拟合。在下一部分的联系中你将实现正则化的逻辑回归，同时你也可以看到正则化是如何作用在过拟合问题上的。 1234567def mapFeature(X1,X2): degree = 6 out = np.ones(X1.shape) for i in range(1,degree + 1): for j in range(0,i+1): out = np.c_[out,np.power(X1,i-j)*np.power(X2,j)] return out 代价函数和梯度现在你将编码实现计算正则化逻辑回归的代价函数和梯度。回忆一下逻辑回归中正则化的代价函数。 $$ \\large J(\\theta) = \\Huge[ \\large -\\frac{1}{m}\\sum_{i=1}^m y^{(i)}log(h_\\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\\theta(x^{(i)})) \\Huge]\\large + \\frac{\\lambda}{2m}\\sum_{j=1}^n\\theta_j^2 $$ 注意你无需正则化参数 $\\theta_0$。代价函数的梯度是一个向量，定义如下： $$ \\large \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\qquad \\qquad for \\qquad j = 0 \\\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = (\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}) +\\frac{\\lambda}{m}\\theta_j \\qquad \\qquad for \\qquad j\\not ={0} $$ 当你完成函数 costFunctionReg 时，使用初始化为 0 的参数 $\\theta$ 得到的结果应该是0.693。 123456789101112131415161718def costFunctionReg(theta, X, y, my_lambda): m = len(X) h = sigmoid(X.dot(theta)) J = (-1/m)*(( y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h))) ) \\ + my_lambda/(2*m) *(np.sum(np.square(theta),axis=0)) return J# 梯度def gradient(theta,X,y,my_lambda): grad = np.zeros(theta.shape) for j in range(0,len(grad)): h = sigmoid(X.dot(theta)) if j == 0 : grad[j] = (1/m) * np.sum((h-y)*X[:,j],axis=0) else : grad[j] = (1/m) * np.sum((h-y)*X[:,j],axis=0) + my_lambda/m*theta[j] return grad 学习参数与前面的部分相似，这里我们使用 python scipy 库中的 optimize 函数来优化。 123result = op.minimize(fun=costFunctionReg, x0=initial_theta, args=(X, y,my_lambda), method='TNC', jac=gradient)cost = result.funtheta = result.x 绘制决策边界参数 lambda 的不同，会影响最后模型的结果，我们来观察一下。 lambda = 0的时候,从下图中可以看到，这时相当于不进行正则化，已经出现了过拟合的情况， Train Accuracy: 87.28813559322035lambda = 1，此时的效果是最好的， Train Accuracy: 83.05084745762711lambda = 10，此时的 Train Accuracy: 74.57627118644068lambda = 100,此时的 Train Accuracy: 60.16949152542372 123456789101112131415161718192021222324252627282930313233343536# 绘制决策边界def plotDecisionBoundary(theta,X,y,data): # 根据第三列的数据分为两部分显示 data_0 = data[data[:,2]==0] data_1 = data[data[:,2]==1] X_0 = data_0[:,0] y_0 = data_0[:,1] X_1 = data_1[:,0] y_1 = data_1[:,1] fig = plt.figure() plt.scatter(X_0,y_0,marker='o',label='y = 0') plt.scatter(X_1,y_1,marker='v',label='y = 1') # Here is the grid range u = np.linspace(-1, 1.5, 50) v = np.linspace(-1, 1.5, 50) z = np.zeros((u.size, v.size)) # Evaluate z = theta*x over the grid for i in range(0, u.size): for j in range(0, v.size): z[i, j] = np.dot(mapFeature(u[i], v[j]), theta) z = z.T # Plot z = 0 # Notice you need to specify the range [0, 0] cs = plt.contour(u, v, z, levels=[0], colors='r', label='Decision Boundary') plt.legend([cs.collections[0]], ['Decision Boundary']) plt.show()","link":"/post/machine-learning-AndrewNg-ex2/"}],"tags":[{"name":"深度学习","slug":"深度学习","link":"/tags/深度学习/"},{"name":"神经网络","slug":"神经网络","link":"/tags/神经网络/"},{"name":"Mask R-CNN","slug":"Mask-R-CNN","link":"/tags/Mask-R-CNN/"},{"name":"鸟类识别","slug":"鸟类识别","link":"/tags/鸟类识别/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"线性回归","slug":"线性回归","link":"/tags/线性回归/"},{"name":"正则化","slug":"正则化","link":"/tags/正则化/"},{"name":"正规方程","slug":"正规方程","link":"/tags/正规方程/"},{"name":"作业","slug":"作业","link":"/tags/作业/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"逻辑回归","slug":"逻辑回归","link":"/tags/逻辑回归/"},{"name":"逻辑方程","slug":"逻辑方程","link":"/tags/逻辑方程/"}],"categories":[{"name":"学习","slug":"学习","link":"/categories/学习/"}]}